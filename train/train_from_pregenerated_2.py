# ========== çœŸæ­£çš„è¶…åˆ†è¾¨ç‡è®­ç»ƒè„šæœ¬ (4xåˆ†è¾¨ç‡æå‡, RGBå½©è‰²) ==========
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import random
import numpy as np
from PIL import Image
import torch.nn.functional as F
import json
import time

# å¯¼å…¥Real-ESRGANæ¨¡å‹
from basicsr.archs.rrdbnet_arch import RRDBNet

# ========== è®­ç»ƒé…ç½®å‚æ•° ==========
HR_DATA_ROOT = './OST'  # é«˜åˆ†è¾¨ç‡å›¾åƒç›®å½•
LR_DATA_ROOT = './OST_LR'  # é¢„ç”Ÿæˆçš„ä½åˆ†è¾¨ç‡å›¾åƒç›®å½•
SCALE_FACTOR = 4  # ä½¿ç”¨çš„é™è´¨å€æ•°
BATCH_SIZE = 1  # æ‰¹æ¬¡å¤§å° (å‡å°ä»¥é€‚åº”æ›´å¤§çš„å›¾åƒ)
NUM_EPOCHS = 20  # è®­ç»ƒè½®æ•°
LR = 5e-4  # å­¦ä¹ ç‡ (é™ä½ä»¥è·å¾—æ›´ç¨³å®šçš„è®­ç»ƒ)
NUM_WORKERS = 0  # æ•°æ®åŠ è½½è¿›ç¨‹æ•°
MODEL_SAVE_PATH = './realESRGAN_4x_super_resolution.pth'
VAL_SPLIT = 0.1  # éªŒè¯é›†æ¯”ä¾‹

# ========== è¶…åˆ†è¾¨ç‡æ¨¡å‹é…ç½® ==========
# çœŸæ­£çš„è¶…åˆ†è¾¨ç‡é…ç½® - RGBå½©è‰²å›¾åƒ
MODEL_CONFIGS = {
    'ultra_lite': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 32, 'num_block': 12, 'num_grow_ch': 16
    },
    'lite': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 48, 'num_block': 16, 'num_grow_ch': 24
    },
    'standard': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 64, 'num_block': 23, 'num_grow_ch': 32
    }
}

CURRENT_MODEL = 'lite'  # é€‰æ‹©æ¨¡å‹å¤æ‚åº¦

# ========== GPUä¼˜åŒ–è®¾ç½® ==========
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
torch.backends.cudnn.benchmark = True

# ========== è¶…åˆ†è¾¨ç‡æ•°æ®é›†ç±» ==========
class SuperResolutionDataset(Dataset):
    """çœŸæ­£çš„è¶…åˆ†è¾¨ç‡æ•°æ®é›† - ä½åˆ†è¾¨ç‡è¾“å…¥åˆ°é«˜åˆ†è¾¨ç‡è¾“å‡º"""
    
    def __init__(self, hr_root, lr_root, scale_factor, image_pairs):
        self.hr_root = hr_root
        self.lr_root = lr_root
        self.scale_factor = scale_factor
        self.image_pairs = image_pairs
        
        print(f"è¶…åˆ†è¾¨ç‡æ•°æ®é›†åˆå§‹åŒ–: {len(image_pairs)} ä¸ªå›¾åƒå¯¹")
        print(f"ä»»åŠ¡: {256}Ã—{256} RGB â†’ {1024}Ã—{1024} RGB (4xè¶…åˆ†è¾¨ç‡)")
    
    def __len__(self):
        return len(self.image_pairs)
    
    def __getitem__(self, idx):
        hr_path, lr_upsampled_path = self.image_pairs[idx]
        
        try:
            # åŠ è½½é«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆGround Truthï¼‰- 1024x1024
            hr_img = self.load_hr_image(hr_path)
            
            # åŠ è½½ä½åˆ†è¾¨ç‡å›¾åƒï¼ˆæ¨¡å‹è¾“å…¥ï¼‰- 256x256
            lr_img = self.load_lr_image(lr_upsampled_path)
            
            # è½¬æ¢ä¸ºtensor (å·²ç»æ˜¯CHWæ ¼å¼)
            lr_tensor = torch.from_numpy(lr_img).float()
            hr_tensor = torch.from_numpy(hr_img).float()
            
            return lr_tensor, hr_tensor
        
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾åƒå¯¹å¤±è´¥: {hr_path}, {lr_upsampled_path}, é”™è¯¯: {e}")
            # è¿”å›éšæœºæ•°æ®ä½œä¸ºfallback
            lr_tensor = torch.rand(3, 256, 256) * 0.8   # RGBä½åˆ†è¾¨ç‡
            hr_tensor = torch.rand(3, 1024, 1024)       # RGBé«˜åˆ†è¾¨ç‡
            return lr_tensor, hr_tensor
    
    def load_hr_image(self, img_path):
        """åŠ è½½é«˜åˆ†è¾¨ç‡å›¾åƒ - ç›®æ ‡è¾“å‡º"""
        img = Image.open(img_path).convert('RGB')
        img = np.array(img).astype('float32') / 255.0
        
        # é«˜åˆ†è¾¨ç‡ç›®æ ‡å°ºå¯¸: 1024x1024
        target_size = 1024
        if img.shape[:2] != (target_size, target_size):
            img_pil = Image.fromarray((img * 255).astype('uint8'))
            img_pil_resized = img_pil.resize((target_size, target_size), Image.LANCZOS)
            img = np.array(img_pil_resized).astype('float32') / 255.0
        
        # è½¬æ¢ä¸ºCHWæ ¼å¼ (channels, height, width)
        img = np.transpose(img, (2, 0, 1))  # HWC -> CHW
        return img
    
    def load_lr_image(self, img_path):
        """åŠ è½½ä½åˆ†è¾¨ç‡å›¾åƒ - æ¨¡å‹è¾“å…¥"""
        img = Image.open(img_path).convert('RGB')
        img = np.array(img).astype('float32') / 255.0
        
        # ä½åˆ†è¾¨ç‡è¾“å…¥å°ºå¯¸: 256x256 (1024/4)
        target_size = 256
        if img.shape[:2] != (target_size, target_size):
            img_pil = Image.fromarray((img * 255).astype('uint8'))
            img_pil_resized = img_pil.resize((target_size, target_size), Image.LANCZOS)
            img = np.array(img_pil_resized).astype('float32') / 255.0
        
        # è½¬æ¢ä¸ºCHWæ ¼å¼ (channels, height, width)
        img = np.transpose(img, (2, 0, 1))  # HWC -> CHW
        return img

# ========== æ•°æ®é…å¯¹å‡½æ•° ==========
def find_image_pairs(hr_root, lr_root, scale_factor):
    """
    æ‰¾åˆ°é«˜åˆ†è¾¨ç‡å›¾åƒå’Œå¯¹åº”çš„ä½åˆ†è¾¨ç‡å›¾åƒå¯¹
    Returns:
        image_pairs: [(hr_path, lr_upsampled_path), ...] çš„åˆ—è¡¨
    """
    image_pairs = []
    lr_scale_dir = os.path.join(lr_root, f'scale_{scale_factor}x')
    
    if not os.path.exists(lr_scale_dir):
        print(f"âŒ ä½åˆ†è¾¨ç‡ç›®å½•ä¸å­˜åœ¨: {lr_scale_dir}")
        return []
    
    print(f"ğŸ” æœç´¢è¶…åˆ†è¾¨ç‡å›¾åƒå¯¹...")
    print(f"  é«˜åˆ†è¾¨ç‡ç›®å½•: {hr_root}")
    print(f"  ä½åˆ†è¾¨ç‡ç›®å½•: {lr_scale_dir}")
    
    # éå†é«˜åˆ†è¾¨ç‡å›¾åƒç›®å½•
    for category in os.listdir(hr_root):
        hr_category_path = os.path.join(hr_root, category)
        lr_category_path = os.path.join(lr_scale_dir, category)
        
        if not os.path.isdir(hr_category_path) or not os.path.exists(lr_category_path):
            continue
        
        category_pairs = 0
        for hr_filename in os.listdir(hr_category_path):
            hr_path = os.path.join(hr_category_path, hr_filename)
            
            if not os.path.isfile(hr_path):
                continue
            
            # æ„å»ºå¯¹åº”çš„ä½åˆ†è¾¨ç‡ä¸Šé‡‡æ ·å›¾åƒè·¯å¾„
            base_name = os.path.splitext(hr_filename)[0]
            lr_upsampled_filename = f"{base_name}_upsampled_{scale_factor}x.png"
            lr_upsampled_path = os.path.join(lr_category_path, lr_upsampled_filename)
            
            if os.path.exists(lr_upsampled_path):
                image_pairs.append((hr_path, lr_upsampled_path))
                category_pairs += 1
        
        print(f"  ç±»åˆ« {category}: {category_pairs} ä¸ªå›¾åƒå¯¹")
    
    print(f"âœ… æ€»è®¡æ‰¾åˆ° {len(image_pairs)} ä¸ªæœ‰æ•ˆå›¾åƒå¯¹")
    return image_pairs

# ========== è®­ç»ƒå‡½æ•° ==========
def train_super_resolution():
    """è¶…åˆ†è¾¨ç‡æ¨¡å‹è®­ç»ƒ"""
    print("=" * 70)
    print("ğŸš€ Real-ESRGAN 4xè¶…åˆ†è¾¨ç‡è®­ç»ƒ (RGBå½©è‰²å›¾åƒ)")
    print("=" * 70)
    
    # æ£€æŸ¥ç›®å½•å­˜åœ¨æ€§
    if not os.path.exists(HR_DATA_ROOT):
        print(f"âŒ é«˜åˆ†è¾¨ç‡æ•°æ®ç›®å½•ä¸å­˜åœ¨: {HR_DATA_ROOT}")
        return
    
    if not os.path.exists(LR_DATA_ROOT):
        print(f"âŒ ä½åˆ†è¾¨ç‡æ•°æ®ç›®å½•ä¸å­˜åœ¨: {LR_DATA_ROOT}")
        print(f"è¯·å…ˆè¿è¡Œ generate_lr_images.py ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒ")
        return
    
    # æ‰¾åˆ°å›¾åƒå¯¹
    image_pairs = find_image_pairs(HR_DATA_ROOT, LR_DATA_ROOT, SCALE_FACTOR)
    if len(image_pairs) == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å›¾åƒå¯¹!")
        return
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    random.shuffle(image_pairs)
    split_idx = int(len(image_pairs) * (1 - VAL_SPLIT))
    train_pairs = image_pairs[:split_idx]
    val_pairs = image_pairs[split_idx:]
    
    print(f"ğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(train_pairs)} ä¸ªå›¾åƒå¯¹")
    print(f"  éªŒè¯é›†: {len(val_pairs)} ä¸ªå›¾åƒå¯¹")
    
    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    train_dataset = SuperResolutionDataset(HR_DATA_ROOT, LR_DATA_ROOT, SCALE_FACTOR, train_pairs)
    val_dataset = SuperResolutionDataset(HR_DATA_ROOT, LR_DATA_ROOT, SCALE_FACTOR, val_pairs)
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=True, 
        num_workers=NUM_WORKERS,
        pin_memory=torch.cuda.is_available()
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, 
        num_workers=NUM_WORKERS,
        pin_memory=torch.cuda.is_available()
    )
    
    # è®¾ç½®è®¾å¤‡å’Œæ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ è®­ç»ƒè®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        torch.cuda.empty_cache()
    
    # åˆ›å»ºæ¨¡å‹
    model_config = MODEL_CONFIGS[CURRENT_MODEL]
    model = RRDBNet(**model_config)
    model = model.to(device)
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ§  æ¨¡å‹é…ç½®: {CURRENT_MODEL}")
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"âš™ï¸  æ¨¡å‹è¯¦æƒ…: {model_config}")
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.L1Loss()
    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer, max_lr=LR, epochs=NUM_EPOCHS, 
        steps_per_epoch=len(train_loader), pct_start=0.1
    )
    
    # è®­ç»ƒé…ç½®ä¿¡æ¯
    print(f"\nğŸš€ è¶…åˆ†è¾¨ç‡è®­ç»ƒé…ç½®:")
    print(f"  è¾“å…¥å°ºå¯¸: 256Ã—256 RGB")
    print(f"  è¾“å‡ºå°ºå¯¸: 1024Ã—1024 RGB")
    print(f"  æ”¾å¤§å€æ•°: {SCALE_FACTOR}x")
    print(f"  æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"  è®­ç»ƒè½®æ•°: {NUM_EPOCHS}")
    print(f"  å­¦ä¹ ç‡: {LR}")
    print(f"  ä»»åŠ¡ç±»å‹: çœŸæ­£çš„è¶…åˆ†è¾¨ç‡é‡å»º")
    
    # å¼€å§‹è®­ç»ƒ
    best_val_loss = float('inf')
    training_start_time = time.time()
    
    training_log = {
        'config': model_config,
        'task_type': '4x_super_resolution',
        'input_size': [256, 256],
        'output_size': [1024, 1024],
        'epochs': [],
        'best_val_loss': float('inf'),
        'total_time': 0
    }
    
    for epoch in range(NUM_EPOCHS):
        epoch_start_time = time.time()
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        
        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - è®­ç»ƒ')
        
        for batch_idx, (lr_img, hr_img) in enumerate(train_pbar):
            lr_img = lr_img.to(device, non_blocking=True)
            hr_img = hr_img.to(device, non_blocking=True)
            
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            pred = model(lr_img)
            
            # ç¡®ä¿é¢„æµ‹ç»“æœä¸ç›®æ ‡å°ºå¯¸ä¸€è‡´
            if pred.shape[-2:] != hr_img.shape[-2:]:
                pred = F.interpolate(pred, size=hr_img.shape[-2:], mode='bilinear', align_corners=False)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(pred, hr_img)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            scheduler.step()
            
            batch_loss = loss.item()
            train_loss += batch_loss
            
            # æ›´æ–°è¿›åº¦æ¡
            train_pbar.set_postfix({
                'Loss': f'{batch_loss:.4f}',
                'LR': f'{optimizer.param_groups[0]["lr"]:.2e}',
                'In': f'{lr_img.shape[-2:]}',
                'Out': f'{pred.shape[-2:]}'
            })
            
            # å®šæœŸæ¸…ç†GPUå†…å­˜
            if batch_idx % 20 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        train_loss /= len(train_loader)
        
        # éªŒè¯é˜¶æ®µï¼ˆæ¯2ä¸ªepochä¸€æ¬¡ï¼ŒèŠ‚çœæ—¶é—´ï¼‰
        val_loss = None
        if (epoch + 1) % 2 == 0 or epoch == NUM_EPOCHS - 1:
            model.eval()
            val_loss = 0
            with torch.no_grad():
                val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - éªŒè¯', leave=False)
                for lr_img, hr_img in val_pbar:
                    lr_img = lr_img.to(device, non_blocking=True)
                    hr_img = hr_img.to(device, non_blocking=True)
                    
                    pred = model(lr_img)
                    if pred.shape[-2:] != hr_img.shape[-2:]:
                        pred = F.interpolate(pred, size=hr_img.shape[-2:], mode='bilinear', align_corners=False)
                    
                    loss = criterion(pred, hr_img)
                    val_loss += loss.item()
                    
                    val_pbar.set_postfix({'Val Loss': f'{loss.item():.4f}'})
            
            val_loss /= len(val_loader)
            
            # ä¿å­˜æœ€ä¼˜æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                torch.save(model.state_dict(), MODEL_SAVE_PATH)
                print(f'[ä¿å­˜] æœ€ä½³è¶…åˆ†è¾¨ç‡æ¨¡å‹ Epoch {epoch+1} | éªŒè¯æŸå¤±={val_loss:.4f}')
        
        epoch_time = time.time() - epoch_start_time
        
        # è®°å½•è®­ç»ƒæ—¥å¿—
        epoch_log = {
            'epoch': epoch + 1,
            'train_loss': train_loss,
            'val_loss': val_loss if val_loss is not None else "æœªè®¡ç®—",
            'time': epoch_time,
            'lr': optimizer.param_groups[0]['lr']
        }
        training_log['epochs'].append(epoch_log)
        
        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
        if val_loss is not None:
            print(f'Epoch {epoch+1}: è®­ç»ƒæŸå¤±={train_loss:.4f}, éªŒè¯æŸå¤±={val_loss:.4f}, æ—¶é—´={epoch_time:.1f}s')
        else:
            print(f'Epoch {epoch+1}: è®­ç»ƒæŸå¤±={train_loss:.4f}, éªŒè¯æŸå¤±=è·³è¿‡éªŒè¯, æ—¶é—´={epoch_time:.1f}s')
        
        # GPUå†…å­˜çŠ¶æ€
        if torch.cuda.is_available() and (epoch + 1) % 3 == 0:
            allocated = torch.cuda.memory_allocated() / 1024**3
            print(f'GPUå†…å­˜: {allocated:.2f}GB')
    
    # è®­ç»ƒå®Œæˆç»Ÿè®¡
    total_time = time.time() - training_start_time
    training_log['total_time'] = total_time
    training_log['best_val_loss'] = best_val_loss if best_val_loss != float('inf') else None
    
    # ä¿å­˜è®­ç»ƒæ—¥å¿—
    log_file = MODEL_SAVE_PATH.replace('.pth', '_training_log.json')
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(training_log, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ è¶…åˆ†è¾¨ç‡è®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    print(f"âš¡ å¹³å‡æ¯è½®: {total_time/NUM_EPOCHS:.1f} ç§’")
    print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}" if best_val_loss != float('inf') else "ğŸ† æœªè¿›è¡ŒéªŒè¯")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {MODEL_SAVE_PATH}")
    print(f"ğŸ“Š è®­ç»ƒæ—¥å¿—: {log_file}")
    print(f"ğŸ” æ¨¡å‹èƒ½åŠ›: 256Ã—256 RGB â†’ 1024Ã—1024 RGB (4xè¶…åˆ†è¾¨ç‡)")

# ========== ä¸»å‡½æ•° ==========
if __name__ == '__main__':
    print("æ£€æŸ¥è¶…åˆ†è¾¨ç‡é¢„ç”Ÿæˆæ•°æ®...")
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨é¢„ç”Ÿæˆçš„æ•°æ®
    lr_scale_dir = os.path.join(LR_DATA_ROOT, f'scale_{SCALE_FACTOR}x')
    if not os.path.exists(lr_scale_dir):
        print(f"âŒ æœªæ‰¾åˆ°é¢„ç”Ÿæˆçš„ä½åˆ†è¾¨ç‡æ•°æ®: {lr_scale_dir}")
        print("è¯·å…ˆè¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒ:")
        print(f"python generate_lr_images.py --scales {SCALE_FACTOR}")
        exit(1)
    
    # å¼€å§‹è¶…åˆ†è¾¨ç‡è®­ç»ƒ
    train_super_resolution()
