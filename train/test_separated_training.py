# ========== åˆ†ç¦»å¼è®­ç»ƒæ–¹æ¡ˆå¿«é€Ÿæµ‹è¯•è„šæœ¬ ==========
import os
import subprocess
import sys
import time

def run_command(cmd, description, check_success=True):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºç»“æœ"""
    print(f"\n{'='*50}")
    print(f"ğŸš€ {description}")
    print(f"{'='*50}")
    print(f"æ‰§è¡Œå‘½ä»¤: {cmd}")
    
    start_time = time.time()
    
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, encoding='utf-8')
        elapsed_time = time.time() - start_time
        
        print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {elapsed_time:.2f}ç§’")
        
        if result.stdout:
            print(f"ğŸ“¤ è¾“å‡º:")
            print(result.stdout)
        
        if result.stderr:
            print(f"âš ï¸  é”™è¯¯è¾“å‡º:")
            print(result.stderr)
        
        if result.returncode == 0:
            print(f"âœ… {description} æˆåŠŸå®Œæˆ!")
            return True
        else:
            print(f"âŒ {description} å¤±è´¥! è¿”å›ç : {result.returncode}")
            if check_success:
                return False
            return True
            
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå‘½ä»¤æ—¶å‡ºé”™: {e}")
        return False

def check_requirements():
    """æ£€æŸ¥å¿…è¦çš„æ–‡ä»¶å’Œç›®å½•"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–...")
    
    # æ£€æŸ¥OSTæ•°æ®é›†
    if not os.path.exists('./OST'):
        print("âŒ OSTæ•°æ®é›†ç›®å½•ä¸å­˜åœ¨!")
        print("è¯·ç¡®ä¿OSTæ–‡ä»¶å¤¹åœ¨å½“å‰ç›®å½•ä¸­")
        return False
    
    # æ£€æŸ¥è„šæœ¬æ–‡ä»¶
    required_files = [
        'generate_lr_images.py',
        'train_from_pregenerated.py'
    ]
    
    for file in required_files:
        if not os.path.exists(file):
            print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {file}")
            return False
    
    print("âœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡!")
    return True

def quick_test():
    """å¿«é€Ÿæµ‹è¯•åˆ†ç¦»å¼è®­ç»ƒæ–¹æ¡ˆ"""
    print("ğŸ¯ å¼€å§‹åˆ†ç¦»å¼è®­ç»ƒæ–¹æ¡ˆå¿«é€Ÿæµ‹è¯•")
    print("æ­¤æµ‹è¯•ä½¿ç”¨å°‘é‡æ•°æ®éªŒè¯æ•´ä¸ªæµç¨‹")
    
    if not check_requirements():
        return False
    
    # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå°‘é‡ä½åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œæµ‹è¯•
    print("\nğŸ“Š ç¬¬1æ­¥ï¼šç”Ÿæˆæµ‹è¯•ç”¨ä½åˆ†è¾¨ç‡å›¾åƒ")
    cmd1 = "python generate_lr_images.py --sample 0.02 --size 256 --scales 4 --auto"
    success1 = run_command(cmd1, "ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒï¼ˆ2%é‡‡æ ·ï¼Œ256x256ï¼‰")
    
    if not success1:
        print("âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œåœæ­¢æµ‹è¯•")
        return False
    
    # æ£€æŸ¥ç”Ÿæˆç»“æœ
    lr_dir = "./OST_LR/scale_4x"
    if os.path.exists(lr_dir):
        # ç»Ÿè®¡ç”Ÿæˆçš„æ–‡ä»¶æ•°é‡
        total_files = 0
        for root, dirs, files in os.walk(lr_dir):
            total_files += len([f for f in files if f.endswith('.png')])
        print(f"âœ… æˆåŠŸç”Ÿæˆ {total_files} ä¸ªä½åˆ†è¾¨ç‡å›¾åƒæ–‡ä»¶")
    else:
        print("âŒ æœªæ‰¾åˆ°ç”Ÿæˆçš„ä½åˆ†è¾¨ç‡å›¾åƒç›®å½•")
        return False
    
    # ç¬¬äºŒæ­¥ï¼šä½¿ç”¨é¢„ç”Ÿæˆæ•°æ®è¿›è¡Œå¿«é€Ÿè®­ç»ƒ
    print("\nğŸ§  ç¬¬2æ­¥ï¼šä½¿ç”¨é¢„ç”Ÿæˆæ•°æ®è®­ç»ƒæ¨¡å‹")
    print("ä¿®æ”¹è®­ç»ƒå‚æ•°ä»¥è¿›è¡Œå¿«é€Ÿæµ‹è¯•...")
    
    # åˆ›å»ºå¿«é€Ÿæµ‹è¯•é…ç½®çš„è®­ç»ƒè„šæœ¬
    create_quick_test_trainer()
    
    cmd2 = "python train_quick_test.py"
    success2 = run_command(cmd2, "å¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ˆ3ä¸ªepochï¼‰")
    
    if not success2:
        print("âŒ è®­ç»ƒæµ‹è¯•å¤±è´¥")
        return False
    
    # ç¬¬ä¸‰æ­¥ï¼šéªŒè¯ç»“æœ
    print("\nğŸ¯ ç¬¬3æ­¥ï¼šéªŒè¯æµ‹è¯•ç»“æœ")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    model_files = [
        'realESRGAN_quick_test.pth',
        'realESRGAN_quick_test_training_log.json'
    ]
    
    for model_file in model_files:
        if os.path.exists(model_file):
            print(f"âœ… æ‰¾åˆ°è¾“å‡ºæ–‡ä»¶: {model_file}")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶: {model_file}")
    
    # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
    print("\nğŸ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
    print("=" * 50)
    print("ğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print("âœ… æ•°æ®é¢„å¤„ç†ï¼šæˆåŠŸ")
    print("âœ… æ¨¡å‹è®­ç»ƒï¼šæˆåŠŸ") 
    print("âœ… æ–‡ä»¶è¾“å‡ºï¼šæˆåŠŸ")
    print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("1. å¦‚æœæµ‹è¯•ç»“æœæ»¡æ„ï¼Œå¯ä»¥ä½¿ç”¨å®Œæ•´æ•°æ®é›†:")
    print("   python generate_lr_images.py --auto")
    print("   python train_from_pregenerated.py")
    print("2. æˆ–è€…é€æ­¥å¢åŠ æ•°æ®é‡è¿›è¡ŒéªŒè¯")
    print("3. è°ƒæ•´æ¨¡å‹å¤æ‚åº¦å’Œè®­ç»ƒå‚æ•°")
    
    return True

def create_quick_test_trainer():
    """åˆ›å»ºå¿«é€Ÿæµ‹è¯•ç”¨çš„è®­ç»ƒè„šæœ¬"""
    quick_trainer_content = '''# ========== å¿«é€Ÿæµ‹è¯•è®­ç»ƒè„šæœ¬ ==========
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import random
import numpy as np
from PIL import Image
import torch.nn.functional as F
import json
import time

# å¯¼å…¥Real-ESRGANæ¨¡å‹
from basicsr.archs.rrdbnet_arch import RRDBNet

# ========== å¿«é€Ÿæµ‹è¯•é…ç½® ==========
HR_DATA_ROOT = './OST'
LR_DATA_ROOT = './OST_LR'
SCALE_FACTOR = 4
BATCH_SIZE = 1  # å°æ‰¹æ¬¡ç”¨äºå¿«é€Ÿæµ‹è¯•
NUM_EPOCHS = 3  # å°‘æ•°epochè¿›è¡Œå¿«é€ŸéªŒè¯
LR = 2e-3
NUM_WORKERS = 0
MODEL_SAVE_PATH = './realESRGAN_quick_test.pth'
VAL_SPLIT = 0.2

# è¶…è½»é‡æ¨¡å‹é…ç½®
MODEL_CONFIG = {
    'num_in_ch': 1, 'num_out_ch': 1,
    'num_feat': 16, 'num_block': 4, 'num_grow_ch': 8
}

os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
torch.backends.cudnn.benchmark = True

class QuickTestDataset(Dataset):
    def __init__(self, hr_root, lr_root, scale_factor, image_pairs):
        self.hr_root = hr_root
        self.lr_root = lr_root
        self.scale_factor = scale_factor
        self.image_pairs = image_pairs
        print(f"å¿«é€Ÿæµ‹è¯•æ•°æ®é›†: {len(image_pairs)} ä¸ªå›¾åƒå¯¹")
    
    def __len__(self):
        return len(self.image_pairs)
    
    def __getitem__(self, idx):
        hr_path, lr_upsampled_path = self.image_pairs[idx]
        
        try:
            hr_img = self.load_image(hr_path)
            lr_img = self.load_image(lr_upsampled_path)
            
            lr_tensor = torch.from_numpy(lr_img).unsqueeze(0).float()
            hr_tensor = torch.from_numpy(hr_img).unsqueeze(0).float()
            
            return lr_tensor, hr_tensor
        except Exception as e:
            print(f"åŠ è½½å¤±è´¥: {hr_path}, é”™è¯¯: {e}")
            size = 256
            lr_tensor = torch.rand(1, size, size) * 0.8
            hr_tensor = torch.rand(1, size, size)
            return lr_tensor, hr_tensor
    
    def load_image(self, img_path):
        img = Image.open(img_path).convert('L')
        img = np.array(img).astype('float32') / 255.0
        return img

def find_image_pairs(hr_root, lr_root, scale_factor):
    image_pairs = []
    lr_scale_dir = os.path.join(lr_root, f'scale_{scale_factor}x')
    
    if not os.path.exists(lr_scale_dir):
        print(f"âŒ ä½åˆ†è¾¨ç‡ç›®å½•ä¸å­˜åœ¨: {lr_scale_dir}")
        return []
    
    print(f"ğŸ” æœç´¢å›¾åƒå¯¹...")
    for category in os.listdir(hr_root):
        hr_category_path = os.path.join(hr_root, category)
        lr_category_path = os.path.join(lr_scale_dir, category)
        
        if not os.path.isdir(hr_category_path) or not os.path.exists(lr_category_path):
            continue
        
        for hr_filename in os.listdir(hr_category_path):
            hr_path = os.path.join(hr_category_path, hr_filename)
            
            if not os.path.isfile(hr_path):
                continue
            
            base_name = os.path.splitext(hr_filename)[0]
            lr_upsampled_filename = f"{base_name}_upsampled_{scale_factor}x.png"
            lr_upsampled_path = os.path.join(lr_category_path, lr_upsampled_filename)
            
            if os.path.exists(lr_upsampled_path):
                image_pairs.append((hr_path, lr_upsampled_path))
    
    print(f"âœ… æ‰¾åˆ° {len(image_pairs)} ä¸ªæœ‰æ•ˆå›¾åƒå¯¹")
    return image_pairs

def main():
    print("ğŸš€ å¼€å§‹å¿«é€Ÿæµ‹è¯•è®­ç»ƒ...")
    
    image_pairs = find_image_pairs(HR_DATA_ROOT, LR_DATA_ROOT, SCALE_FACTOR)
    if len(image_pairs) == 0:
        print("âŒ æœªæ‰¾åˆ°å›¾åƒå¯¹!")
        return
    
    # æ•°æ®åˆ’åˆ†
    random.shuffle(image_pairs)
    split_idx = int(len(image_pairs) * (1 - VAL_SPLIT))
    train_pairs = image_pairs[:split_idx]
    val_pairs = image_pairs[split_idx:] if split_idx < len(image_pairs) else image_pairs[-2:]
    
    print(f"è®­ç»ƒé›†: {len(train_pairs)}, éªŒè¯é›†: {len(val_pairs)}")
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = QuickTestDataset(HR_DATA_ROOT, LR_DATA_ROOT, SCALE_FACTOR, train_pairs)
    val_dataset = QuickTestDataset(HR_DATA_ROOT, LR_DATA_ROOT, SCALE_FACTOR, val_pairs)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
    
    # è®¾å¤‡å’Œæ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}")
    
    model = RRDBNet(**MODEL_CONFIG)
    model = model.to(device)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.3f}M)")
    
    # ä¼˜åŒ–å™¨
    criterion = nn.L1Loss()
    optimizer = optim.Adam(model.parameters(), lr=LR)
    
    # è®­ç»ƒ
    best_val_loss = float('inf')
    training_log = {'epochs': [], 'best_val_loss': float('inf')}
    
    print(f"å¼€å§‹ {NUM_EPOCHS} ä¸ªepochçš„å¿«é€Ÿè®­ç»ƒ...")
    
    for epoch in range(NUM_EPOCHS):
        epoch_start = time.time()
        
        # è®­ç»ƒ
        model.train()
        train_loss = 0
        
        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')
        for lr_img, hr_img in train_pbar:
            lr_img, hr_img = lr_img.to(device), hr_img.to(device)
            
            optimizer.zero_grad()
            pred = model(lr_img)
            
            if pred.shape[-2:] != hr_img.shape[-2:]:
                pred = F.interpolate(pred, size=hr_img.shape[-2:], mode='bilinear', align_corners=False)
            
            loss = criterion(pred, hr_img)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            train_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})
        
        train_loss /= len(train_loader)
        
        # éªŒè¯
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for lr_img, hr_img in val_loader:
                lr_img, hr_img = lr_img.to(device), hr_img.to(device)
                pred = model(lr_img)
                if pred.shape[-2:] != hr_img.shape[-2:]:
                    pred = F.interpolate(pred, size=hr_img.shape[-2:], mode='bilinear', align_corners=False)
                loss = criterion(pred, hr_img)
                val_loss += loss.item()
        
        val_loss /= len(val_loader)
        
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            print(f'[ä¿å­˜] æœ€ä½³æ¨¡å‹ Epoch {epoch+1} | éªŒè¯æŸå¤±={val_loss:.4f}')
        
        epoch_time = time.time() - epoch_start
        epoch_log = {
            'epoch': epoch + 1,
            'train_loss': train_loss,
            'val_loss': val_loss,
            'time': epoch_time
        }
        training_log['epochs'].append(epoch_log)
        
        print(f'Epoch {epoch+1}: Train={train_loss:.4f}, Val={val_loss:.4f}, Time={epoch_time:.1f}s')
    
    training_log['best_val_loss'] = best_val_loss
    
    # ä¿å­˜æ—¥å¿—
    log_file = MODEL_SAVE_PATH.replace('.pth', '_training_log.json')
    with open(log_file, 'w') as f:
        json.dump(training_log, f, indent=2)
    
    print(f"\\nğŸ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
    print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")
    print(f"æ¨¡å‹ä¿å­˜: {MODEL_SAVE_PATH}")
    print(f"æ—¥å¿—ä¿å­˜: {log_file}")

if __name__ == '__main__':
    main()
'''
    
    with open('train_quick_test.py', 'w', encoding='utf-8') as f:
        f.write(quick_trainer_content)
    
    print("âœ… åˆ›å»ºå¿«é€Ÿæµ‹è¯•è®­ç»ƒè„šæœ¬: train_quick_test.py")

def cleanup_test_files():
    """æ¸…ç†æµ‹è¯•æ–‡ä»¶"""
    print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ–‡ä»¶...")
    
    files_to_remove = [
        'train_quick_test.py',
        'realESRGAN_quick_test.pth',
        'realESRGAN_quick_test_training_log.json'
    ]
    
    for file in files_to_remove:
        if os.path.exists(file):
            try:
                os.remove(file)
                print(f"âœ… åˆ é™¤: {file}")
            except Exception as e:
                print(f"âš ï¸  åˆ é™¤å¤±è´¥: {file}, é”™è¯¯: {e}")
    
    # è¯¢é—®æ˜¯å¦åˆ é™¤ç”Ÿæˆçš„ä½åˆ†è¾¨ç‡æ•°æ®
    response = input("\nâ“ æ˜¯å¦åˆ é™¤æµ‹è¯•ç”Ÿæˆçš„ä½åˆ†è¾¨ç‡æ•°æ®ç›®å½• OST_LR? (y/n): ").lower().strip()
    if response == 'y':
        import shutil
        try:
            if os.path.exists('./OST_LR'):
                shutil.rmtree('./OST_LR')
                print("âœ… åˆ é™¤æµ‹è¯•æ•°æ®ç›®å½•: OST_LR")
        except Exception as e:
            print(f"âš ï¸  åˆ é™¤ç›®å½•å¤±è´¥: {e}")

if __name__ == '__main__':
    print("ğŸ¯ åˆ†ç¦»å¼è®­ç»ƒæ–¹æ¡ˆå¿«é€Ÿæµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    try:
        success = quick_test()
        
        if success:
            print(f"\\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
            print("ğŸš€ åˆ†ç¦»å¼è®­ç»ƒæ–¹æ¡ˆå·¥ä½œæ­£å¸¸ï¼Œå¯ä»¥æŠ•å…¥ä½¿ç”¨!")
        else:
            print(f"\\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜")
            print("è¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤ç›¸å…³é—®é¢˜")
    
    except KeyboardInterrupt:
        print(f"\\nâš ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
    
    finally:
        # è¯¢é—®æ˜¯å¦æ¸…ç†æµ‹è¯•æ–‡ä»¶
        response = input("\\nâ“ æ˜¯å¦æ¸…ç†æµ‹è¯•è¿‡ç¨‹ä¸­ç”Ÿæˆçš„æ–‡ä»¶? (y/n): ").lower().strip()
        if response == 'y':
            cleanup_test_files()
        
        print("\\nğŸ‘‹ æµ‹è¯•å®Œæˆï¼Œæ„Ÿè°¢ä½¿ç”¨!")
