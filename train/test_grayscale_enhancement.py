# ========== Real-ESRGAN ç°åº¦å›¾åƒå¢å¼ºæµ‹è¯•è„šæœ¬ ==========
import os
import torch
import numpy as np
from PIL import Image
import time
import argparse

# å¯¼å…¥Real-ESRGANæ¨¡å‹
from basicsr.archs.rrdbnet_arch import RRDBNet

# ========== æ¨¡å‹é…ç½® ==========
MODEL_CONFIGS = {
    'ultra_lite': {
        'num_in_ch': 1, 'num_out_ch': 1,  # ç°åº¦å›¾åƒ
        'num_feat': 24, 'num_block': 8, 'num_grow_ch': 12
    },
    'lite': {
        'num_in_ch': 1, 'num_out_ch': 1,  # ç°åº¦å›¾åƒ
        'num_feat': 32, 'num_block': 12, 'num_grow_ch': 16
    },
    'standard': {
        'num_in_ch': 1, 'num_out_ch': 1,  # ç°åº¦å›¾åƒ
        'num_feat': 48, 'num_block': 16, 'num_grow_ch': 24
    }
}

class GrayscaleEnhancer:
    """ç°åº¦å›¾åƒå¢å¼ºå™¨"""
    
    def __init__(self, model_path, model_config='ultra_lite', device=None):
        self.model_path = model_path
        self.model_config = model_config
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.target_size = 512  # å›ºå®šå¤„ç†å°ºå¯¸
        
        # åŠ è½½æ¨¡å‹
        self.model = self.load_model()
        
        print(f"ğŸš€ ç°åº¦å›¾åƒå¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“± è®¾å¤‡: {self.device}")
        print(f"ğŸ§  æ¨¡å‹é…ç½®: {model_config}")
        print(f"ğŸ“„ æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"ğŸ” åŠŸèƒ½: ç°åº¦å›¾åƒè´¨é‡å¢å¼º")
        print(f"ğŸ“ å¤„ç†å°ºå¯¸: {self.target_size}Ã—{self.target_size}")
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        config = MODEL_CONFIGS[self.model_config]
        model = RRDBNet(**config)
        
        if os.path.exists(self.model_path):
            print(f"âœ… åŠ è½½æ¨¡å‹æƒé‡: {self.model_path}")
            state_dict = torch.load(self.model_path, map_location=self.device)
            model.load_state_dict(state_dict)
        else:
            print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            print("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•")
        
        model.to(self.device)
        model.eval()
        
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
        
        return model
    
    def preprocess_image(self, image_path):
        """é¢„å¤„ç†è¾“å…¥å›¾åƒ"""
        # åŠ è½½å›¾åƒå¹¶è½¬æ¢ä¸ºç°åº¦
        img = Image.open(image_path).convert('L')
        original_size = img.size
        
        # è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
        if img.size != (self.target_size, self.target_size):
            img = img.resize((self.target_size, self.target_size), Image.LANCZOS)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–
        img_array = np.array(img).astype('float32') / 255.0
        
        # æ·»åŠ batchå’Œchannelç»´åº¦
        img_tensor = torch.from_numpy(img_array).unsqueeze(0).unsqueeze(0).to(self.device)
        
        return img_tensor, original_size
    
    def postprocess_image(self, tensor, target_size=None):
        """åå¤„ç†è¾“å‡ºtensor"""
        # ç§»é™¤batchå’Œchannelç»´åº¦
        tensor = tensor.squeeze(0).squeeze(0)
        
        # è£å‰ªåˆ°[0,1]èŒƒå›´
        tensor = torch.clamp(tensor, 0, 1)
        
        # è½¬æ¢ä¸ºnumpy
        img_array = tensor.cpu().numpy()
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        img_array = (img_array * 255).astype('uint8')
        img_pil = Image.fromarray(img_array, mode='L')
        
        # å¦‚æœéœ€è¦è°ƒæ•´å›åŸå§‹å°ºå¯¸
        if target_size and img_pil.size != target_size:
            img_pil = img_pil.resize(target_size, Image.LANCZOS)
        
        return img_pil
    
    def enhance_single(self, input_path, output_path, preserve_size=True):
        """å¯¹å•å¼ å›¾åƒè¿›è¡Œå¢å¼º"""
        start_time = time.time()
        
        # é¢„å¤„ç†
        img_tensor, original_size = self.preprocess_image(input_path)
        
        print(f"ğŸ“¥ è¾“å…¥å›¾åƒ: {input_path}")
        print(f"ğŸ“ åŸå§‹å°ºå¯¸: {original_size}")
        print(f"ğŸ“ å¤„ç†å°ºå¯¸: {img_tensor.shape}")
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            enhanced_tensor = self.model(img_tensor)
        
        print(f"ğŸ“ è¾“å‡ºå°ºå¯¸: {enhanced_tensor.shape}")
        
        # åå¤„ç†
        target_size = original_size if preserve_size else None
        enhanced_image = self.postprocess_image(enhanced_tensor, target_size)
        
        # ä¿å­˜ç»“æœ
        enhanced_image.save(output_path)
        
        process_time = time.time() - start_time
        
        print(f"ğŸ’¾ è¾“å‡ºå›¾åƒ: {output_path}")
        print(f"ğŸ“ æœ€ç»ˆå°ºå¯¸: {enhanced_image.size}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {process_time:.2f}ç§’")
        print(f"ğŸ¯ å¢å¼ºç±»å‹: ç°åº¦å›¾åƒè´¨é‡å¢å¼º")
        
        return enhanced_image
    
    def enhance_batch(self, input_dir, output_dir, max_images=None, preserve_size=True):
        """æ‰¹é‡å¢å¼ºå¤„ç†"""
        if not os.path.exists(input_dir):
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return
        
        os.makedirs(output_dir, exist_ok=True)
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for file in os.listdir(input_dir):
            if os.path.splitext(file.lower())[1] in supported_formats:
                image_files.append(file)
        
        if max_images:
            image_files = image_files[:max_images]
        
        print(f"ğŸ” æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒè¿›è¡Œå¢å¼º")
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        total_start_time = time.time()
        
        for i, filename in enumerate(image_files, 1):
            input_path = os.path.join(input_dir, filename)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            name, ext = os.path.splitext(filename)
            output_filename = f"{name}_enhanced.png"
            output_path = os.path.join(output_dir, output_filename)
            
            print(f"\n[{i}/{len(image_files)}] å¤„ç†: {filename}")
            
            try:
                self.enhance_single(input_path, output_path, preserve_size)
                print(f"âœ… å®Œæˆ")
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
        
        total_time = time.time() - total_start_time
        print(f"\nğŸ‰ æ‰¹é‡å¢å¼ºå®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’")
        print(f"âš¡ å¹³å‡æ¯å¼ : {total_time/len(image_files):.1f}ç§’")
    
    def compare_results(self, original_path, enhanced_path):
        """æ¯”è¾ƒåŸå§‹å’Œå¢å¼ºç»“æœ"""
        # åŠ è½½å›¾åƒ
        original_img = Image.open(original_path).convert('L')
        enhanced_img = Image.open(enhanced_path).convert('L')
        
        print(f"\nğŸ“Š å¢å¼ºç»“æœæ¯”è¾ƒ:")
        print(f"ğŸ”¹ åŸå§‹å›¾åƒ: {original_img.size}")
        print(f"ğŸ”¹ å¢å¼ºå›¾åƒ: {enhanced_img.size}")
        
        # åˆ›å»ºå¯¹æ¯”å›¾åƒ
        target_size = max(original_img.size[0], enhanced_img.size[0])
        original_resized = original_img.resize((target_size, target_size), Image.LANCZOS)
        enhanced_resized = enhanced_img.resize((target_size, target_size), Image.LANCZOS)
        
        # åˆ›å»ºæ°´å¹³æ‹¼æ¥çš„å¯¹æ¯”å›¾
        comparison = Image.new('L', (target_size * 2, target_size))
        comparison.paste(original_resized, (0, 0))
        comparison.paste(enhanced_resized, (target_size, 0))
        
        comparison_path = enhanced_path.replace('.png', '_comparison.png')
        comparison.save(comparison_path)
        print(f"ğŸ’¾ å¯¹æ¯”å›¾åƒ: {comparison_path}")
        print(f"ğŸ“‹ å¸ƒå±€: åŸå§‹å›¾åƒ | å¢å¼ºå›¾åƒ")
        
        return comparison

def main():
    parser = argparse.ArgumentParser(description='Real-ESRGAN ç°åº¦å›¾åƒå¢å¼ºæµ‹è¯•')
    parser.add_argument('--model', type=str, default='./realESRGAN_from_pregenerated.pth',
                        help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--config', type=str, default='ultra_lite', 
                        choices=['ultra_lite', 'lite', 'standard'],
                        help='æ¨¡å‹é…ç½®')
    parser.add_argument('--input', type=str, required=True,
                        help='è¾“å…¥å›¾åƒæˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--output', type=str, required=True,
                        help='è¾“å‡ºå›¾åƒæˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--mode', type=str, default='single', 
                        choices=['single', 'batch'],
                        help='å¤„ç†æ¨¡å¼')
    parser.add_argument('--max_images', type=int, default=None,
                        help='æ‰¹é‡å¤„ç†æ—¶çš„æœ€å¤§å›¾åƒæ•°é‡')
    parser.add_argument('--preserve_size', action='store_true', default=True,
                        help='ä¿æŒåŸå§‹å›¾åƒå°ºå¯¸')
    parser.add_argument('--compare', action='store_true',
                        help='ç”Ÿæˆå¯¹æ¯”å›¾åƒ')
    
    args = parser.parse_args()
    
    # åˆ›å»ºå¢å¼ºå™¨
    enhancer = GrayscaleEnhancer(args.model, args.config)
    
    if args.mode == 'single':
        # å•å¼ å›¾åƒå¤„ç†
        print(f"\nğŸ¯ å•å¼ ç°åº¦å›¾åƒå¢å¼º")
        enhanced_image = enhancer.enhance_single(args.input, args.output, args.preserve_size)
        
        # å¦‚æœéœ€è¦ç”Ÿæˆå¯¹æ¯”å›¾åƒ
        if args.compare:
            enhancer.compare_results(args.input, args.output)
    
    elif args.mode == 'batch':
        # æ‰¹é‡å¤„ç†
        print(f"\nğŸ¯ æ‰¹é‡ç°åº¦å›¾åƒå¢å¼º")
        enhancer.enhance_batch(args.input, args.output, args.max_images, args.preserve_size)

if __name__ == '__main__':
    print("=" * 70)
    print("ğŸš€ Real-ESRGAN ç°åº¦å›¾åƒå¢å¼ºæµ‹è¯•å·¥å…·")
    print("=" * 70)
    
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œæ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    import sys
    if len(sys.argv) == 1:
        print("ğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        print("\n1. å•å¼ å›¾åƒå¢å¼º:")
        print("   python test_grayscale_enhancement.py --input image.jpg --output enhanced.png --mode single")
        print("\n2. å•å¼ å›¾åƒå¢å¼ºï¼ˆå¸¦å¯¹æ¯”ï¼‰:")
        print("   python test_grayscale_enhancement.py --input image.jpg --output enhanced.png --mode single --compare")
        print("\n3. æ‰¹é‡å¤„ç†:")
        print("   python test_grayscale_enhancement.py --input ./inputs --output ./outputs --mode batch")
        print("\n4. ä½¿ç”¨ä¸åŒæ¨¡å‹é…ç½®:")
        print("   python test_grayscale_enhancement.py --input image.jpg --output enhanced.png --config lite")
        print("\nğŸ“ å‚æ•°è¯´æ˜:")
        print("   --model: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ (é»˜è®¤: ./realESRGAN_from_pregenerated.pth)")
        print("   --config: æ¨¡å‹é…ç½® (ultra_lite/lite/standard)")
        print("   --input: è¾“å…¥å›¾åƒæˆ–ç›®å½•")
        print("   --output: è¾“å‡ºå›¾åƒæˆ–ç›®å½•")
        print("   --mode: å¤„ç†æ¨¡å¼ (single/batch)")
        print("   --preserve_size: ä¿æŒåŸå§‹å°ºå¯¸")
        print("   --compare: ç”Ÿæˆå¯¹æ¯”å›¾åƒ")
        print("\nğŸ” åŠŸèƒ½: ç°åº¦å›¾åƒè´¨é‡å¢å¼º (512Ã—512å¤„ç†)")
        sys.exit(0)
    
    main()
