# ========== å›¾åƒæ¸…æ™°åº¦å¢å¼ºè®­ç»ƒè„šæœ¬ (å°ºå¯¸ä¸å˜, è´¨é‡æå‡) ==========
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm
import random
import numpy as np
from PIL import Image, ImageFilter
import torch.nn.functional as F
import json
import time
import cv2

# å¯¼å…¥Real-ESRGANæ¨¡å‹
from basicsr.archs.rrdbnet_arch import RRDBNet

# ========== è®­ç»ƒé…ç½®å‚æ•° ==========
HR_DATA_ROOT = './OST'  # é«˜è´¨é‡å›¾åƒç›®å½•
LR_DATA_ROOT = './OST_LQ'  # ç”Ÿæˆçš„ä½è´¨é‡å›¾åƒç›®å½•
IMAGE_SIZE = 512  # å›ºå®šå›¾åƒå°ºå¯¸ï¼ˆè¾“å…¥è¾“å‡ºç›¸åŒï¼‰
BATCH_SIZE = 2  # æ‰¹æ¬¡å¤§å°
NUM_EPOCHS = 25  # è®­ç»ƒè½®æ•°
LR = 2e-4  # å­¦ä¹ ç‡
NUM_WORKERS = 0  # æ•°æ®åŠ è½½è¿›ç¨‹æ•°
MODEL_SAVE_PATH = './realESRGAN_quality_enhancement.pth'
VAL_SPLIT = 0.1  # éªŒè¯é›†æ¯”ä¾‹

# ========== å›¾åƒè´¨é‡å¢å¼ºæ¨¡å‹é…ç½® ==========
# ä¸“é—¨ç”¨äºè´¨é‡å¢å¼ºçš„é…ç½® - RGBå½©è‰²å›¾åƒ
MODEL_CONFIGS = {
    'ultra_lite': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 32, 'num_block': 10, 'num_grow_ch': 16
    },
    'lite': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 48, 'num_block': 16, 'num_grow_ch': 24
    },
    'standard': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 64, 'num_block': 20, 'num_grow_ch': 32
    }
}

CURRENT_MODEL = 'lite'  # é€‰æ‹©æ¨¡å‹å¤æ‚åº¦

# ========== GPUä¼˜åŒ–è®¾ç½® ==========
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
torch.backends.cudnn.benchmark = True

# ========== å›¾åƒè´¨é‡é™è§£å‡½æ•° ==========
def add_degradation(img, degradation_type='mixed'):
    """
    å¯¹é«˜è´¨é‡å›¾åƒæ·»åŠ å„ç§é™è§£æ•ˆæœï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„ä½è´¨é‡å›¾åƒ
    
    Args:
        img: PILå›¾åƒ
        degradation_type: é™è§£ç±»å‹
    
    Returns:
        degraded_img: é™è§£åçš„PILå›¾åƒ
    """
    if degradation_type == 'blur':
        # æ¨¡ç³Šé™è§£
        blur_radius = random.uniform(0.5, 2.0)
        img = img.filter(ImageFilter.GaussianBlur(blur_radius))
    
    elif degradation_type == 'noise':
        # å™ªå£°é™è§£
        img_array = np.array(img).astype('float32')
        noise_std = random.uniform(5, 25)
        noise = np.random.normal(0, noise_std, img_array.shape)
        img_array = np.clip(img_array + noise, 0, 255)
        img = Image.fromarray(img_array.astype('uint8'))
    
    elif degradation_type == 'jpeg':
        # JPEGå‹ç¼©é™è§£
        import io
        quality = random.randint(30, 70)
        buffer = io.BytesIO()
        img.save(buffer, format='JPEG', quality=quality)
        buffer.seek(0)
        img = Image.open(buffer)
    
    elif degradation_type == 'mixed':
        # æ··åˆé™è§£ï¼ˆæœ€çœŸå®ï¼‰
        # 1. å…ˆæ·»åŠ è½»å¾®æ¨¡ç³Š
        if random.random() < 0.7:
            blur_radius = random.uniform(0.3, 1.2)
            img = img.filter(ImageFilter.GaussianBlur(blur_radius))
        
        # 2. æ·»åŠ å™ªå£°
        if random.random() < 0.6:
            img_array = np.array(img).astype('float32')
            noise_std = random.uniform(3, 15)
            noise = np.random.normal(0, noise_std, img_array.shape)
            img_array = np.clip(img_array + noise, 0, 255)
            img = Image.fromarray(img_array.astype('uint8'))
        
        # 3. JPEGå‹ç¼©
        if random.random() < 0.8:
            import io
            quality = random.randint(40, 80)
            buffer = io.BytesIO()
            img.save(buffer, format='JPEG', quality=quality)
            buffer.seek(0)
            img = Image.open(buffer)
    
    return img

# ========== å›¾åƒè´¨é‡å¢å¼ºæ•°æ®é›†ç±» ==========
class QualityEnhancementDataset(Dataset):
    """å›¾åƒè´¨é‡å¢å¼ºæ•°æ®é›† - ç›¸åŒå°ºå¯¸çš„ä½è´¨é‡åˆ°é«˜è´¨é‡"""
    
    def __init__(self, hr_root, image_files, image_size=512):
        self.hr_root = hr_root
        self.image_files = image_files
        self.image_size = image_size
        
        print(f"å›¾åƒè´¨é‡å¢å¼ºæ•°æ®é›†åˆå§‹åŒ–: {len(image_files)} å¼ å›¾åƒ")
        print(f"ä»»åŠ¡: {image_size}Ã—{image_size} RGB ä½è´¨é‡ â†’ {image_size}Ã—{image_size} RGB é«˜è´¨é‡")
        print(f"ç›®æ ‡: æå‡æ¸…æ™°åº¦ã€å»å™ªã€å»æ¨¡ç³Šï¼ˆå°ºå¯¸ä¸å˜ï¼‰")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        img_path = self.image_files[idx]
        
        try:
            # åŠ è½½åŸå§‹é«˜è´¨é‡å›¾åƒ
            hr_img = self.load_image(img_path)
            
            # åˆ›å»ºä½è´¨é‡ç‰ˆæœ¬ï¼ˆåœ¨çº¿é™è§£ï¼‰
            hr_pil = self.tensor_to_pil(hr_img)
            lq_pil = add_degradation(hr_pil, 'mixed')
            lq_img = self.pil_to_tensor(lq_pil)
            
            return lq_img, hr_img
        
        except Exception as e:
            print(f"âŒ åŠ è½½å›¾åƒå¤±è´¥: {img_path}, é”™è¯¯: {e}")
            # è¿”å›éšæœºæ•°æ®ä½œä¸ºfallback
            lq_tensor = torch.rand(3, self.image_size, self.image_size) * 0.8
            hr_tensor = torch.rand(3, self.image_size, self.image_size)
            return lq_tensor, hr_tensor
    
    def load_image(self, img_path):
        """åŠ è½½å›¾åƒå¹¶è½¬æ¢ä¸ºtensor"""
        img = Image.open(img_path).convert('RGB')
        
        # è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
        if img.size != (self.image_size, self.image_size):
            img = img.resize((self.image_size, self.image_size), Image.LANCZOS)
        
        # è½¬æ¢ä¸ºtensor
        img_array = np.array(img).astype('float32') / 255.0
        img_tensor = torch.from_numpy(np.transpose(img_array, (2, 0, 1))).float()
        
        return img_tensor
    
    def tensor_to_pil(self, tensor):
        """tensorè½¬PILå›¾åƒ"""
        img_array = tensor.numpy()
        img_array = np.transpose(img_array, (1, 2, 0))
        img_array = (img_array * 255).astype('uint8')
        return Image.fromarray(img_array)
    
    def pil_to_tensor(self, pil_img):
        """PILå›¾åƒè½¬tensor"""
        img_array = np.array(pil_img).astype('float32') / 255.0
        return torch.from_numpy(np.transpose(img_array, (2, 0, 1))).float()

# ========== æ”¶é›†å›¾åƒæ–‡ä»¶å‡½æ•° ==========
def collect_image_files(hr_root):
    """æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶è·¯å¾„"""
    image_files = []
    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
    
    print(f"ğŸ” æœç´¢å›¾åƒæ–‡ä»¶...")
    print(f"  å›¾åƒç›®å½•: {hr_root}")
    
    # éå†æ‰€æœ‰å­ç›®å½•
    for root, dirs, files in os.walk(hr_root):
        for file in files:
            if os.path.splitext(file.lower())[1] in supported_formats:
                img_path = os.path.join(root, file)
                image_files.append(img_path)
    
    print(f"âœ… æ€»è®¡æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    return image_files

# ========== è®­ç»ƒå‡½æ•° ==========
def train_quality_enhancement():
    """å›¾åƒè´¨é‡å¢å¼ºæ¨¡å‹è®­ç»ƒ"""
    print("=" * 70)
    print("ğŸš€ Real-ESRGAN å›¾åƒè´¨é‡å¢å¼ºè®­ç»ƒ (RGBå½©è‰²å›¾åƒ)")
    print("=" * 70)
    
    # æ£€æŸ¥ç›®å½•å­˜åœ¨æ€§
    if not os.path.exists(HR_DATA_ROOT):
        print(f"âŒ é«˜è´¨é‡å›¾åƒç›®å½•ä¸å­˜åœ¨: {HR_DATA_ROOT}")
        return
    
    # æ”¶é›†æ‰€æœ‰å›¾åƒæ–‡ä»¶
    image_files = collect_image_files(HR_DATA_ROOT)
    if len(image_files) == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶!")
        return
    
    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    random.shuffle(image_files)
    split_idx = int(len(image_files) * (1 - VAL_SPLIT))
    train_files = image_files[:split_idx]
    val_files = image_files[split_idx:]
    
    print(f"ğŸ“Š æ•°æ®é›†åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(train_files)} å¼ å›¾åƒ")
    print(f"  éªŒè¯é›†: {len(val_files)} å¼ å›¾åƒ")
    
    # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    train_dataset = QualityEnhancementDataset(HR_DATA_ROOT, train_files, IMAGE_SIZE)
    val_dataset = QualityEnhancementDataset(HR_DATA_ROOT, val_files, IMAGE_SIZE)
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=True, 
        num_workers=NUM_WORKERS,
        pin_memory=torch.cuda.is_available()
    )
    
    val_loader = DataLoader(
        val_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False, 
        num_workers=NUM_WORKERS,
        pin_memory=torch.cuda.is_available()
    )
    
    # è®¾ç½®è®¾å¤‡å’Œæ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ”§ è®­ç»ƒè®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name(0)}")
        torch.cuda.empty_cache()
    
    # åˆ›å»ºæ¨¡å‹
    model_config = MODEL_CONFIGS[CURRENT_MODEL]
    model = RRDBNet(**model_config)
    model = model.to(device)
    
    # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ§  æ¨¡å‹é…ç½®: {CURRENT_MODEL}")
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"âš™ï¸  æ¨¡å‹è¯¦æƒ…: {model_config}")
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.L1Loss()
    # æ·»åŠ æ„ŸçŸ¥æŸå¤±ä¼šæ›´å¥½ï¼Œä½†è¿™é‡Œå…ˆç”¨L1
    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer, max_lr=LR, epochs=NUM_EPOCHS, 
        steps_per_epoch=len(train_loader), pct_start=0.1
    )
    
    # è®­ç»ƒé…ç½®ä¿¡æ¯
    print(f"\nğŸš€ å›¾åƒè´¨é‡å¢å¼ºè®­ç»ƒé…ç½®:")
    print(f"  è¾“å…¥å°ºå¯¸: {IMAGE_SIZE}Ã—{IMAGE_SIZE} RGB")
    print(f"  è¾“å‡ºå°ºå¯¸: {IMAGE_SIZE}Ã—{IMAGE_SIZE} RGB")
    print(f"  æ”¾å¤§å€æ•°: 1x (å°ºå¯¸ä¸å˜)")
    print(f"  æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"  è®­ç»ƒè½®æ•°: {NUM_EPOCHS}")
    print(f"  å­¦ä¹ ç‡: {LR}")
    print(f"  ä»»åŠ¡ç±»å‹: å›¾åƒè´¨é‡å¢å¼ºï¼ˆå»æ¨¡ç³Šã€å»å™ªã€ç»†èŠ‚æ¢å¤ï¼‰")
    
    # å¼€å§‹è®­ç»ƒ
    best_val_loss = float('inf')
    training_start_time = time.time()
    
    training_log = {
        'config': model_config,
        'task_type': 'quality_enhancement',
        'input_size': [IMAGE_SIZE, IMAGE_SIZE],
        'output_size': [IMAGE_SIZE, IMAGE_SIZE],
        'epochs': [],
        'best_val_loss': float('inf'),
        'total_time': 0
    }
    
    for epoch in range(NUM_EPOCHS):
        epoch_start_time = time.time()
        
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        
        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - è®­ç»ƒ')
        
        for batch_idx, (lq_img, hq_img) in enumerate(train_pbar):
            lq_img = lq_img.to(device, non_blocking=True)
            hq_img = hq_img.to(device, non_blocking=True)
            
            optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            pred = model(lq_img)
            
            # è®¡ç®—æŸå¤±
            loss = criterion(pred, hq_img)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            scheduler.step()
            
            batch_loss = loss.item()
            train_loss += batch_loss
            
            # æ›´æ–°è¿›åº¦æ¡
            train_pbar.set_postfix({
                'Loss': f'{batch_loss:.4f}',
                'LR': f'{optimizer.param_groups[0]["lr"]:.2e}',
                'In': f'{lq_img.shape[-2:]}',
                'Out': f'{pred.shape[-2:]}'
            })
            
            # å®šæœŸæ¸…ç†GPUå†…å­˜
            if batch_idx % 30 == 0 and torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        train_loss /= len(train_loader)
        
        # éªŒè¯é˜¶æ®µï¼ˆæ¯2ä¸ªepochä¸€æ¬¡ï¼‰
        val_loss = None
        if (epoch + 1) % 2 == 0 or epoch == NUM_EPOCHS - 1:
            model.eval()
            val_loss = 0
            with torch.no_grad():
                val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - éªŒè¯', leave=False)
                for lq_img, hq_img in val_pbar:
                    lq_img = lq_img.to(device, non_blocking=True)
                    hq_img = hq_img.to(device, non_blocking=True)
                    
                    pred = model(lq_img)
                    loss = criterion(pred, hq_img)
                    val_loss += loss.item()
                    
                    val_pbar.set_postfix({'Val Loss': f'{loss.item():.4f}'})
            
            val_loss /= len(val_loader)
            
            # ä¿å­˜æœ€ä¼˜æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                torch.save(model.state_dict(), MODEL_SAVE_PATH)
                print(f'[ä¿å­˜] æœ€ä½³è´¨é‡å¢å¼ºæ¨¡å‹ Epoch {epoch+1} | éªŒè¯æŸå¤±={val_loss:.4f}')
        
        epoch_time = time.time() - epoch_start_time
        
        # è®°å½•è®­ç»ƒæ—¥å¿—
        epoch_log = {
            'epoch': epoch + 1,
            'train_loss': train_loss,
            'val_loss': val_loss if val_loss is not None else "æœªè®¡ç®—",
            'time': epoch_time,
            'lr': optimizer.param_groups[0]['lr']
        }
        training_log['epochs'].append(epoch_log)
        
        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
        if val_loss is not None:
            print(f'Epoch {epoch+1}: è®­ç»ƒæŸå¤±={train_loss:.4f}, éªŒè¯æŸå¤±={val_loss:.4f}, æ—¶é—´={epoch_time:.1f}s')
        else:
            print(f'Epoch {epoch+1}: è®­ç»ƒæŸå¤±={train_loss:.4f}, éªŒè¯æŸå¤±=è·³è¿‡éªŒè¯, æ—¶é—´={epoch_time:.1f}s')
        
        # GPUå†…å­˜çŠ¶æ€
        if torch.cuda.is_available() and (epoch + 1) % 3 == 0:
            allocated = torch.cuda.memory_allocated() / 1024**3
            print(f'GPUå†…å­˜: {allocated:.2f}GB')
    
    # è®­ç»ƒå®Œæˆç»Ÿè®¡
    total_time = time.time() - training_start_time
    training_log['total_time'] = total_time
    training_log['best_val_loss'] = best_val_loss if best_val_loss != float('inf') else None
    
    # ä¿å­˜è®­ç»ƒæ—¥å¿—
    log_file = MODEL_SAVE_PATH.replace('.pth', '_training_log.json')
    with open(log_file, 'w', encoding='utf-8') as f:
        json.dump(training_log, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ å›¾åƒè´¨é‡å¢å¼ºè®­ç»ƒå®Œæˆ!")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.1f} åˆ†é’Ÿ")
    print(f"âš¡ å¹³å‡æ¯è½®: {total_time/NUM_EPOCHS:.1f} ç§’")
    print(f"ğŸ† æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}" if best_val_loss != float('inf') else "ğŸ† æœªè¿›è¡ŒéªŒè¯")
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {MODEL_SAVE_PATH}")
    print(f"ğŸ“Š è®­ç»ƒæ—¥å¿—: {log_file}")
    print(f"ğŸ” æ¨¡å‹èƒ½åŠ›: {IMAGE_SIZE}Ã—{IMAGE_SIZE} RGB è´¨é‡å¢å¼º")
    print(f"ğŸ¯ åŠŸèƒ½: å»æ¨¡ç³Šã€å»å™ªã€ç»†èŠ‚æ¢å¤ï¼ˆå°ºå¯¸ä¸å˜ï¼‰")

# ========== ä¸»å‡½æ•° ==========
if __name__ == '__main__':
    print("å¼€å§‹å›¾åƒè´¨é‡å¢å¼ºè®­ç»ƒ...")
    
    # æ£€æŸ¥é«˜è´¨é‡å›¾åƒç›®å½•
    if not os.path.exists(HR_DATA_ROOT):
        print(f"âŒ é«˜è´¨é‡å›¾åƒç›®å½•ä¸å­˜åœ¨: {HR_DATA_ROOT}")
        print("è¯·ç¡®ä¿OSTç›®å½•åŒ…å«é«˜è´¨é‡çš„è®­ç»ƒå›¾åƒ")
        exit(1)
    
    # å¼€å§‹è´¨é‡å¢å¼ºè®­ç»ƒ
    train_quality_enhancement()
