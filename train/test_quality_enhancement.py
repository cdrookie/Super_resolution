# ========== å›¾åƒè´¨é‡å¢å¼ºæµ‹è¯•è„šæœ¬ ==========
import os
import torch
import numpy as np
from PIL import Image, ImageFilter
import time
import argparse

# å¯¼å…¥Real-ESRGANæ¨¡å‹
from basicsr.archs.rrdbnet_arch import RRDBNet

# ========== æ¨¡å‹é…ç½® ==========
MODEL_CONFIGS = {
    'ultra_lite': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 32, 'num_block': 10, 'num_grow_ch': 16
    },
    'lite': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 48, 'num_block': 16, 'num_grow_ch': 24
    },
    'standard': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 64, 'num_block': 20, 'num_grow_ch': 32
    }
}

class QualityEnhancer:
    """å›¾åƒè´¨é‡å¢å¼ºå™¨"""
    
    def __init__(self, model_path, model_config='lite', device=None):
        self.model_path = model_path
        self.model_config = model_config
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½æ¨¡å‹
        self.model = self.load_model()
        
        print(f"ğŸš€ å›¾åƒè´¨é‡å¢å¼ºå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“± è®¾å¤‡: {self.device}")
        print(f"ğŸ§  æ¨¡å‹é…ç½®: {model_config}")
        print(f"ğŸ“„ æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"ğŸ” åŠŸèƒ½: å›¾åƒè´¨é‡å¢å¼ºï¼ˆå»æ¨¡ç³Šã€å»å™ªã€ç»†èŠ‚æ¢å¤ï¼‰")
        print(f"ğŸ“ å°ºå¯¸: ä¿æŒåŸå§‹å°ºå¯¸ä¸å˜")
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„è´¨é‡å¢å¼ºæ¨¡å‹"""
        config = MODEL_CONFIGS[self.model_config]
        model = RRDBNet(**config)
        
        if os.path.exists(self.model_path):
            print(f"âœ… åŠ è½½æ¨¡å‹æƒé‡: {self.model_path}")
            state_dict = torch.load(self.model_path, map_location=self.device)
            model.load_state_dict(state_dict)
        else:
            print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            print("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•")
        
        model.to(self.device)
        model.eval()
        
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
        
        return model
    
    def preprocess_image(self, image_path, target_size=None):
        """é¢„å¤„ç†è¾“å…¥å›¾åƒ"""
        # åŠ è½½å›¾åƒ
        img = Image.open(image_path).convert('RGB')
        original_size = img.size
        
        # å¦‚æœæŒ‡å®šç›®æ ‡å°ºå¯¸ï¼Œè°ƒæ•´å›¾åƒ
        if target_size and img.size != (target_size, target_size):
            img = img.resize((target_size, target_size), Image.LANCZOS)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–
        img_array = np.array(img).astype('float32') / 255.0
        
        # è½¬æ¢ä¸ºCHWæ ¼å¼
        img_array = np.transpose(img_array, (2, 0, 1))  # HWC -> CHW
        
        # æ·»åŠ batchç»´åº¦å¹¶è½¬æ¢ä¸ºtensor
        img_tensor = torch.from_numpy(img_array).unsqueeze(0).to(self.device)
        
        return img_tensor, original_size
    
    def postprocess_image(self, tensor, target_size=None):
        """åå¤„ç†è¾“å‡ºtensor"""
        # ç§»é™¤batchç»´åº¦
        tensor = tensor.squeeze(0)
        
        # è£å‰ªåˆ°[0,1]èŒƒå›´
        tensor = torch.clamp(tensor, 0, 1)
        
        # è½¬æ¢ä¸ºnumpy
        img_array = tensor.cpu().numpy()
        
        # è½¬æ¢ä¸ºHWCæ ¼å¼
        img_array = np.transpose(img_array, (1, 2, 0))  # CHW -> HWC
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        img_array = (img_array * 255).astype('uint8')
        img_pil = Image.fromarray(img_array)
        
        # å¦‚æœéœ€è¦è°ƒæ•´å›åŸå§‹å°ºå¯¸
        if target_size and img_pil.size != target_size:
            img_pil = img_pil.resize(target_size, Image.LANCZOS)
        
        return img_pil
    
    def enhance_single(self, input_path, output_path, preserve_size=True):
        """å¯¹å•å¼ å›¾åƒè¿›è¡Œè´¨é‡å¢å¼º"""
        start_time = time.time()
        
        # é¢„å¤„ç†
        img_tensor, original_size = self.preprocess_image(input_path, 512 if not preserve_size else None)
        
        print(f"ğŸ“¥ è¾“å…¥å›¾åƒ: {input_path}")
        print(f"ğŸ“ åŸå§‹å°ºå¯¸: {original_size}")
        print(f"ğŸ“ å¤„ç†å°ºå¯¸: {img_tensor.shape}")
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            enhanced_tensor = self.model(img_tensor)
        
        print(f"ğŸ“ è¾“å‡ºå°ºå¯¸: {enhanced_tensor.shape}")
        
        # åå¤„ç†
        target_size = original_size if preserve_size else None
        enhanced_image = self.postprocess_image(enhanced_tensor, target_size)
        
        # ä¿å­˜ç»“æœ
        enhanced_image.save(output_path)
        
        process_time = time.time() - start_time
        
        print(f"ğŸ’¾ è¾“å‡ºå›¾åƒ: {output_path}")
        print(f"ğŸ“ æœ€ç»ˆå°ºå¯¸: {enhanced_image.size}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {process_time:.2f}ç§’")
        print(f"ğŸ¯ å¢å¼ºç±»å‹: è´¨é‡æå‡ï¼ˆå»æ¨¡ç³Šã€å»å™ªã€ç»†èŠ‚æ¢å¤ï¼‰")
        
        return enhanced_image
    
    def enhance_batch(self, input_dir, output_dir, max_images=None, preserve_size=True):
        """æ‰¹é‡è´¨é‡å¢å¼ºå¤„ç†"""
        if not os.path.exists(input_dir):
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return
        
        os.makedirs(output_dir, exist_ok=True)
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for file in os.listdir(input_dir):
            if os.path.splitext(file.lower())[1] in supported_formats:
                image_files.append(file)
        
        if max_images:
            image_files = image_files[:max_images]
        
        print(f"ğŸ” æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒè¿›è¡Œè´¨é‡å¢å¼º")
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        total_start_time = time.time()
        
        for i, filename in enumerate(image_files, 1):
            input_path = os.path.join(input_dir, filename)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            name, ext = os.path.splitext(filename)
            output_filename = f"{name}_enhanced.png"
            output_path = os.path.join(output_dir, output_filename)
            
            print(f"\n[{i}/{len(image_files)}] å¤„ç†: {filename}")
            
            try:
                self.enhance_single(input_path, output_path, preserve_size)
                print(f"âœ… å®Œæˆ")
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
        
        total_time = time.time() - total_start_time
        print(f"\nğŸ‰ æ‰¹é‡è´¨é‡å¢å¼ºå®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’")
        print(f"âš¡ å¹³å‡æ¯å¼ : {total_time/len(image_files):.1f}ç§’")
    
    def create_degraded_test(self, input_path, output_dir):
        """åˆ›å»ºé™è§£å›¾åƒç”¨äºå¯¹æ¯”æµ‹è¯•"""
        img = Image.open(input_path).convert('RGB')
        
        os.makedirs(output_dir, exist_ok=True)
        
        base_name = os.path.splitext(os.path.basename(input_path))[0]
        
        # 1. åŸå§‹å›¾åƒ
        original_path = os.path.join(output_dir, f"{base_name}_original.png")
        img.save(original_path)
        
        # 2. æ¨¡ç³Šç‰ˆæœ¬
        blurred = img.filter(ImageFilter.GaussianBlur(1.5))
        blur_path = os.path.join(output_dir, f"{base_name}_blurred.png")
        blurred.save(blur_path)
        
        # 3. å™ªå£°ç‰ˆæœ¬
        img_array = np.array(img).astype('float32')
        noise = np.random.normal(0, 15, img_array.shape)
        noisy_array = np.clip(img_array + noise, 0, 255).astype('uint8')
        noisy = Image.fromarray(noisy_array)
        noise_path = os.path.join(output_dir, f"{base_name}_noisy.png")
        noisy.save(noise_path)
        
        # 4. JPEGå‹ç¼©ç‰ˆæœ¬
        import io
        buffer = io.BytesIO()
        img.save(buffer, format='JPEG', quality=50)
        buffer.seek(0)
        compressed = Image.open(buffer)
        jpeg_path = os.path.join(output_dir, f"{base_name}_compressed.png")
        compressed.save(jpeg_path)
        
        print(f"ğŸ“Š åˆ›å»ºæµ‹è¯•å›¾åƒ:")
        print(f"  åŸå§‹: {original_path}")
        print(f"  æ¨¡ç³Š: {blur_path}")
        print(f"  å™ªå£°: {noise_path}")
        print(f"  å‹ç¼©: {jpeg_path}")
        
        return [original_path, blur_path, noise_path, jpeg_path]
    
    def compare_results(self, original_path, degraded_path, enhanced_path):
        """æ¯”è¾ƒåŸå§‹ã€é™è§£å’Œå¢å¼ºç»“æœ"""
        # åŠ è½½å›¾åƒ
        original_img = Image.open(original_path).convert('RGB')
        degraded_img = Image.open(degraded_path).convert('RGB')
        enhanced_img = Image.open(enhanced_path).convert('RGB')
        
        print(f"\nğŸ“Š è´¨é‡å¢å¼ºç»“æœæ¯”è¾ƒ:")
        print(f"ğŸ”¹ åŸå§‹å›¾åƒ: {original_img.size}")
        print(f"ğŸ”¹ é™è§£å›¾åƒ: {degraded_img.size}")
        print(f"ğŸ”¹ å¢å¼ºå›¾åƒ: {enhanced_img.size}")
        
        # åˆ›å»ºå¯¹æ¯”å›¾åƒ
        target_size = original_img.size
        original_resized = original_img.resize(target_size, Image.LANCZOS)
        degraded_resized = degraded_img.resize(target_size, Image.LANCZOS)
        enhanced_resized = enhanced_img.resize(target_size, Image.LANCZOS)
        
        # åˆ›å»ºæ°´å¹³æ‹¼æ¥çš„å¯¹æ¯”å›¾
        comparison = Image.new('RGB', (target_size[0] * 3, target_size[1]))
        comparison.paste(degraded_resized, (0, 0))
        comparison.paste(enhanced_resized, (target_size[0], 0))
        comparison.paste(original_resized, (target_size[0] * 2, 0))
        
        comparison_path = enhanced_path.replace('.png', '_comparison.png')
        comparison.save(comparison_path)
        print(f"ğŸ’¾ å¯¹æ¯”å›¾åƒ: {comparison_path}")
        print(f"ğŸ“‹ å¸ƒå±€: é™è§£å›¾åƒ | å¢å¼ºå›¾åƒ | åŸå§‹å›¾åƒ")
        
        return comparison

def main():
    parser = argparse.ArgumentParser(description='Real-ESRGAN å›¾åƒè´¨é‡å¢å¼ºæµ‹è¯•')
    parser.add_argument('--model', type=str, default='./realESRGAN_quality_enhancement.pth',
                        help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--config', type=str, default='lite', 
                        choices=['ultra_lite', 'lite', 'standard'],
                        help='æ¨¡å‹é…ç½®')
    parser.add_argument('--input', type=str, required=True,
                        help='è¾“å…¥å›¾åƒæˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--output', type=str, required=True,
                        help='è¾“å‡ºå›¾åƒæˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--mode', type=str, default='single', 
                        choices=['single', 'batch', 'test_degraded'],
                        help='å¤„ç†æ¨¡å¼')
    parser.add_argument('--max_images', type=int, default=None,
                        help='æ‰¹é‡å¤„ç†æ—¶çš„æœ€å¤§å›¾åƒæ•°é‡')
    parser.add_argument('--preserve_size', action='store_true', default=True,
                        help='ä¿æŒåŸå§‹å›¾åƒå°ºå¯¸')
    parser.add_argument('--compare', type=str, default=None,
                        help='ç”¨äºæ¯”è¾ƒçš„åŸå§‹å›¾åƒè·¯å¾„(ä»…å•å¼ æ¨¡å¼)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè´¨é‡å¢å¼ºå™¨
    enhancer = QualityEnhancer(args.model, args.config)
    
    if args.mode == 'single':
        # å•å¼ å›¾åƒå¤„ç†
        print(f"\nğŸ¯ å•å¼ å›¾åƒè´¨é‡å¢å¼º")
        enhanced_image = enhancer.enhance_single(args.input, args.output, args.preserve_size)
        
        # å¦‚æœæä¾›äº†åŸå§‹å›¾åƒè¿›è¡Œæ¯”è¾ƒ
        if args.compare:
            enhancer.compare_results(args.compare, args.input, args.output)
    
    elif args.mode == 'batch':
        # æ‰¹é‡å¤„ç†
        print(f"\nğŸ¯ æ‰¹é‡å›¾åƒè´¨é‡å¢å¼º")
        enhancer.enhance_batch(args.input, args.output, args.max_images, args.preserve_size)
    
    elif args.mode == 'test_degraded':
        # åˆ›å»ºé™è§£æµ‹è¯•å›¾åƒ
        print(f"\nğŸ¯ åˆ›å»ºé™è§£æµ‹è¯•å›¾åƒ")
        test_images = enhancer.create_degraded_test(args.input, args.output)
        
        # å¯¹æ¯ä¸ªé™è§£å›¾åƒè¿›è¡Œå¢å¼º
        for degraded_path in test_images[1:]:  # è·³è¿‡åŸå§‹å›¾åƒ
            name = os.path.basename(degraded_path).replace('.png', '')
            enhanced_path = os.path.join(args.output, f"{name}_enhanced.png")
            enhancer.enhance_single(degraded_path, enhanced_path, args.preserve_size)
            enhancer.compare_results(test_images[0], degraded_path, enhanced_path)

if __name__ == '__main__':
    print("=" * 70)
    print("ğŸš€ Real-ESRGAN å›¾åƒè´¨é‡å¢å¼ºæµ‹è¯•å·¥å…·")
    print("=" * 70)
    
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œæ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    import sys
    if len(sys.argv) == 1:
        print("ğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        print("\n1. å•å¼ å›¾åƒè´¨é‡å¢å¼º:")
        print("   python test_quality_enhancement.py --input blurry.jpg --output clear.png --mode single")
        print("\n2. æ‰¹é‡å¤„ç†:")
        print("   python test_quality_enhancement.py --input ./inputs --output ./outputs --mode batch")
        print("\n3. åˆ›å»ºé™è§£æµ‹è¯•å›¾åƒ:")
        print("   python test_quality_enhancement.py --input high_quality.jpg --output ./test --mode test_degraded")
        print("\n4. ä¸åŸå§‹å›¾åƒå¯¹æ¯”:")
        print("   python test_quality_enhancement.py --input blurry.jpg --output clear.png --compare original.jpg --mode single")
        print("\nğŸ“ å‚æ•°è¯´æ˜:")
        print("   --model: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„")
        print("   --config: æ¨¡å‹é…ç½® (ultra_lite/lite/standard)")
        print("   --input: è¾“å…¥å›¾åƒæˆ–ç›®å½•")
        print("   --output: è¾“å‡ºå›¾åƒæˆ–ç›®å½•")
        print("   --mode: å¤„ç†æ¨¡å¼ (single/batch/test_degraded)")
        print("   --preserve_size: ä¿æŒåŸå§‹å°ºå¯¸")
        print("   --compare: ç”¨äºæ¯”è¾ƒçš„åŸå§‹å›¾åƒ")
        print("\nğŸ” åŠŸèƒ½: å›¾åƒè´¨é‡å¢å¼ºï¼ˆå»æ¨¡ç³Šã€å»å™ªã€ç»†èŠ‚æ¢å¤ï¼Œå°ºå¯¸ä¸å˜ï¼‰")
        sys.exit(0)
    
    main()
