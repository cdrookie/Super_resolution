# ========== OSTæ•°æ®é›†ä½åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆè„šæœ¬ ==========
import os
import numpy as np
import cv2
from PIL import Image
import tifffile
import random
from tqdm import tqdm
import argparse
import json
import time

# ========== é…ç½®å‚æ•° ==========
DATA_ROOT = './OST'  # åŸå§‹æ•°æ®é›†æ ¹ç›®å½•
OUTPUT_ROOT = './OST_LR'  # ä½åˆ†è¾¨ç‡è¾“å‡ºç›®å½•
SCALE_FACTORS = [4]  # é™è´¨å€æ•°ï¼š[2, 3, 4]
TARGET_SIZE = 512  # ç›®æ ‡å›¾åƒå°ºå¯¸
INTERPOLATION_METHOD = cv2.INTER_CUBIC  # æ’å€¼æ–¹æ³•
PROCESS_ALL = True  # æ˜¯å¦å¤„ç†æ‰€æœ‰å›¾åƒï¼ŒFalseåˆ™æŒ‰æ¯”ä¾‹é‡‡æ ·
SAMPLE_RATIO = 1.0  # é‡‡æ ·æ¯”ä¾‹ï¼ˆå½“PROCESS_ALL=Falseæ—¶ä½¿ç”¨ï¼‰

# ========== åˆ†è¾¨ç‡é™è´¨å‡½æ•° ==========
def apply_resolution_degradation(img, scale_factor, method=cv2.INTER_CUBIC):
    """
    åˆ†è¾¨ç‡é™è´¨ï¼šå°†å›¾åƒåˆ†è¾¨ç‡é™ä½æŒ‡å®šå€æ•°
    Args:
        img: è¾“å…¥é«˜åˆ†è¾¨ç‡å›¾åƒ (numpy array)
        scale_factor: é™è´¨å€æ•° (2, 3, 4)
        method: æ’å€¼æ–¹æ³•
    Returns:
        lr_img: ä½åˆ†è¾¨ç‡å›¾åƒ (numpy array)
    """
    h, w = img.shape[:2]
    
    # è®¡ç®—ä½åˆ†è¾¨ç‡å°ºå¯¸
    new_h, new_w = max(1, h // scale_factor), max(1, w // scale_factor)
    
    # ä¸‹é‡‡æ ·åˆ°ä½åˆ†è¾¨ç‡
    lr_img = cv2.resize(img, (new_w, new_h), interpolation=method)
    
    return lr_img

def upsample_to_target_size(img, target_size, method=cv2.INTER_CUBIC):
    """
    å°†ä½åˆ†è¾¨ç‡å›¾åƒä¸Šé‡‡æ ·åˆ°ç›®æ ‡å°ºå¯¸
    Args:
        img: è¾“å…¥ä½åˆ†è¾¨ç‡å›¾åƒ
        target_size: ç›®æ ‡å°ºå¯¸ (int æˆ– tuple)
        method: æ’å€¼æ–¹æ³•
    Returns:
        upsampled_img: ä¸Šé‡‡æ ·åçš„å›¾åƒ
    """
    if isinstance(target_size, int):
        target_size = (target_size, target_size)
    
    upsampled_img = cv2.resize(img, target_size, interpolation=method)
    return upsampled_img

# ========== å›¾åƒè¯»å–å’Œé¢„å¤„ç† ==========
def load_and_preprocess_image(img_path, target_size):
    """
    åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
    Args:
        img_path: å›¾åƒè·¯å¾„
        target_size: ç›®æ ‡å°ºå¯¸
    Returns:
        processed_img: é¢„å¤„ç†åçš„å›¾åƒ (float32, [0,1])
    """
    try:
        ext = os.path.splitext(img_path)[-1].lower()
        
        if ext in ['.tif', '.tiff']:
            # å¤„ç†TIFFæ–‡ä»¶
            img = tifffile.imread(img_path)
            if img.ndim == 3:
                img = img.mean(axis=0)  # è½¬ä¸ºç°åº¦
            img = img.astype('float32')
            # å½’ä¸€åŒ–åˆ°[0,1]
            if img.max() > 1:
                img = img / img.max()
        else:
            # å¤„ç†å¸¸è§„å›¾åƒæ–‡ä»¶
            img = Image.open(img_path).convert('L')
            img = np.array(img).astype('float32') / 255.0
        
        # è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
        if img.shape != (target_size, target_size):
            img = cv2.resize(img, (target_size, target_size), interpolation=INTERPOLATION_METHOD)
        
        return img
    
    except Exception as e:
        print(f"âŒ å¤„ç†å›¾åƒå¤±è´¥: {img_path}, é”™è¯¯: {e}")
        return None

# ========== æ•°æ®æ”¶é›† ==========
def get_all_image_paths(root_dir, sample_ratio=1.0):
    """
    éå†OSTæ–‡ä»¶å¤¹ï¼Œæ”¶é›†æ‰€æœ‰å›¾åƒè·¯å¾„
    Args:
        root_dir: æ•°æ®é›†æ ¹ç›®å½•
        sample_ratio: é‡‡æ ·æ¯”ä¾‹
    Returns:
        image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
        category_info: ç±»åˆ«ä¿¡æ¯å­—å…¸
    """
    image_paths = []
    category_info = {}
    supported_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff']
    
    if not os.path.exists(root_dir):
        print(f"âŒ æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨: '{root_dir}'")
        return [], {}
    
    print(f"ğŸ“‚ æ‰«ææ•°æ®é›†ç›®å½•: {root_dir}")
    
    for subdir in os.listdir(root_dir):
        subpath = os.path.join(root_dir, subdir)
        if not os.path.isdir(subpath):
            continue
        
        print(f"å¤„ç†ç±»åˆ«: {subdir}")
        category_paths = []
        
        for filename in os.listdir(subpath):
            filepath = os.path.join(subpath, filename)
            if os.path.isfile(filepath):
                ext = os.path.splitext(filename)[-1].lower()
                if ext in supported_extensions:
                    category_paths.append(filepath)
        
        # æŒ‰æ¯”ä¾‹é‡‡æ ·
        if sample_ratio < 1.0 and len(category_paths) > 0:
            num_samples = max(1, int(len(category_paths) * sample_ratio))
            category_paths = random.sample(category_paths, num_samples)
        
        image_paths.extend(category_paths)
        category_info[subdir] = len(category_paths)
        print(f"  æ‰¾åˆ° {len(category_paths)} å¼ å›¾åƒ")
    
    print(f"ğŸ“Š æ€»è®¡æ‰¾åˆ° {len(image_paths)} å¼ å›¾åƒ")
    return image_paths, category_info

# ========== æ‰¹é‡å¤„ç†å‡½æ•° ==========
def generate_lr_images(input_paths, output_root, scale_factors, target_size):
    """
    æ‰¹é‡ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒ
    Args:
        input_paths: è¾“å…¥å›¾åƒè·¯å¾„åˆ—è¡¨
        output_root: è¾“å‡ºæ ¹ç›®å½•
        scale_factors: é™è´¨å€æ•°åˆ—è¡¨
        target_size: ç›®æ ‡å›¾åƒå°ºå¯¸
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    os.makedirs(output_root, exist_ok=True)
    
    # ä¸ºæ¯ä¸ªscale factoråˆ›å»ºå­ç›®å½•
    scale_dirs = {}
    for sf in scale_factors:
        scale_dir = os.path.join(output_root, f'scale_{sf}x')
        os.makedirs(scale_dir, exist_ok=True)
        scale_dirs[sf] = scale_dir
        print(f"ğŸ“ åˆ›å»ºè¾“å‡ºç›®å½•: {scale_dir}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'total_processed': 0,
        'total_failed': 0,
        'scale_factor_counts': {sf: 0 for sf in scale_factors},
        'processing_times': []
    }
    
    print(f"ğŸš€ å¼€å§‹å¤„ç† {len(input_paths)} å¼ å›¾åƒ...")
    start_time = time.time()
    
    # ä½¿ç”¨tqdmæ˜¾ç¤ºè¿›åº¦
    for img_path in tqdm(input_paths, desc="ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒ"):
        try:
            # åŠ è½½å’Œé¢„å¤„ç†åŸå§‹å›¾åƒ
            hr_img = load_and_preprocess_image(img_path, target_size)
            if hr_img is None:
                stats['total_failed'] += 1
                continue
            
            # è·å–ç›¸å¯¹è·¯å¾„ä¿¡æ¯ä»¥ä¿æŒç›®å½•ç»“æ„
            rel_path = os.path.relpath(img_path, DATA_ROOT)
            filename = os.path.basename(img_path)
            category = os.path.dirname(rel_path)
            
            # ä¸ºæ¯ä¸ªscale factorç”Ÿæˆä½åˆ†è¾¨ç‡ç‰ˆæœ¬
            for scale_factor in scale_factors:
                process_start = time.time()
                
                # åˆ›å»ºç±»åˆ«å­ç›®å½•
                category_output_dir = os.path.join(scale_dirs[scale_factor], category)
                os.makedirs(category_output_dir, exist_ok=True)
                
                # ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒ
                lr_img = apply_resolution_degradation(hr_img, scale_factor, INTERPOLATION_METHOD)
                
                # ä¸Šé‡‡æ ·å›ç›®æ ‡å°ºå¯¸ï¼ˆç”¨äºè®­ç»ƒæ—¶çš„å°ºå¯¸åŒ¹é…ï¼‰
                lr_upsampled = upsample_to_target_size(lr_img, target_size, INTERPOLATION_METHOD)
                
                # ä¿å­˜å›¾åƒæ—¶ç¡®ä¿å°ºå¯¸å®Œå…¨ä¸€è‡´
                # ä¿å­˜åŸå§‹ä½åˆ†è¾¨ç‡ç‰ˆæœ¬
                lr_filename = f"{os.path.splitext(filename)[0]}_lr_{scale_factor}x.png"
                lr_output_path = os.path.join(category_output_dir, lr_filename)
                lr_img_uint8 = (np.clip(lr_img, 0, 1) * 255).astype(np.uint8)
                # ç¡®ä¿ä¿å­˜çš„å›¾åƒå°ºå¯¸æ­£ç¡®
                if lr_img_uint8.shape != (target_size//scale_factor, target_size//scale_factor):
                    lr_img_uint8 = cv2.resize(lr_img_uint8, (target_size//scale_factor, target_size//scale_factor), interpolation=INTERPOLATION_METHOD)
                cv2.imwrite(lr_output_path, lr_img_uint8)
                
                # ä¿å­˜ä¸Šé‡‡æ ·ç‰ˆæœ¬ï¼ˆç”¨äºè®­ç»ƒï¼‰- ç¡®ä¿å°ºå¯¸å®Œå…¨ä¸€è‡´
                upsampled_filename = f"{os.path.splitext(filename)[0]}_upsampled_{scale_factor}x.png"
                upsampled_output_path = os.path.join(category_output_dir, upsampled_filename)
                upsampled_img_uint8 = (np.clip(lr_upsampled, 0, 1) * 255).astype(np.uint8)
                # å¼ºåˆ¶ç¡®ä¿ä¸Šé‡‡æ ·å›¾åƒå°ºå¯¸ä¸ºç›®æ ‡å°ºå¯¸
                if upsampled_img_uint8.shape != (target_size, target_size):
                    upsampled_img_uint8 = cv2.resize(upsampled_img_uint8, (target_size, target_size), interpolation=INTERPOLATION_METHOD)
                cv2.imwrite(upsampled_output_path, upsampled_img_uint8)
                
                # ç»Ÿè®¡å¤„ç†æ—¶é—´
                process_time = time.time() - process_start
                stats['processing_times'].append(process_time)
                stats['scale_factor_counts'][scale_factor] += 1
            
            stats['total_processed'] += 1
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {img_path}, é”™è¯¯: {e}")
            stats['total_failed'] += 1
    
    total_time = time.time() - start_time
    
    # ä¿å­˜å¤„ç†ç»Ÿè®¡ä¿¡æ¯
    stats['total_time'] = total_time
    stats['avg_time_per_image'] = total_time / len(input_paths) if input_paths else 0
    stats['avg_processing_time'] = np.mean(stats['processing_times']) if stats['processing_times'] else 0
    
    stats_file = os.path.join(output_root, 'processing_stats.json')
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    # æ‰“å°ç»“æœç»Ÿè®¡
    print(f"\nğŸ‰ å¤„ç†å®Œæˆ!")
    print(f"âœ… æˆåŠŸå¤„ç†: {stats['total_processed']} å¼ å›¾åƒ")
    print(f"âŒ å¤„ç†å¤±è´¥: {stats['total_failed']} å¼ å›¾åƒ")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_time/60:.2f} åˆ†é’Ÿ")
    print(f"âš¡ å¹³å‡é€Ÿåº¦: {stats['avg_time_per_image']:.3f} ç§’/å›¾åƒ")
    
    print(f"\nğŸ“Š å„scale factorç»Ÿè®¡:")
    for sf, count in stats['scale_factor_counts'].items():
        print(f"  Scale {sf}x: {count} å¼ å›¾åƒ")
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_root}")
    print(f"ğŸ“„ ç»Ÿè®¡æ–‡ä»¶: {stats_file}")

# ========== è¾“å‡ºç›®å½•ç»“æ„é¢„è§ˆ ==========
def preview_output_structure(output_root, scale_factors, category_info):
    """é¢„è§ˆè¾“å‡ºç›®å½•ç»“æ„"""
    print(f"\nğŸ“‹ è¾“å‡ºç›®å½•ç»“æ„é¢„è§ˆ:")
    print(f"{output_root}/")
    for sf in scale_factors:
        print(f"â”œâ”€â”€ scale_{sf}x/")
        for category, count in category_info.items():
            print(f"â”‚   â”œâ”€â”€ {category}/")
            print(f"â”‚   â”‚   â”œâ”€â”€ image1_lr_{sf}x.png")
            print(f"â”‚   â”‚   â”œâ”€â”€ image1_upsampled_{sf}x.png")
            print(f"â”‚   â”‚   â””â”€â”€ ... ({count*2} ä¸ªæ–‡ä»¶)")
    print(f"â””â”€â”€ processing_stats.json")

# ========== ä¸»å‡½æ•° ==========
def main():
    print("=" * 60)
    print("OSTæ•°æ®é›†ä½åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆè„šæœ¬")
    print("=" * 60)
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {DATA_ROOT}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_ROOT}")
    print(f"ğŸ”¢ é™è´¨å€æ•°: {SCALE_FACTORS}")
    print(f"ğŸ“ ç›®æ ‡å°ºå¯¸: {TARGET_SIZE}x{TARGET_SIZE}")
    print(f"ğŸ¨ æ’å€¼æ–¹æ³•: {INTERPOLATION_METHOD}")
    print(f"ğŸ“Š å¤„ç†æ–¹å¼: {'å…¨éƒ¨å¤„ç†' if PROCESS_ALL else f'æŒ‰æ¯”ä¾‹é‡‡æ ·({SAMPLE_RATIO*100:.1f}%)'}")
    print("=" * 60)
    
    # æ”¶é›†å›¾åƒè·¯å¾„
    image_paths, category_info = get_all_image_paths(
        DATA_ROOT, 
        sample_ratio=1.0 if PROCESS_ALL else SAMPLE_RATIO
    )
    
    if len(image_paths) == 0:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶!")
        return
    
    # é¢„è§ˆè¾“å‡ºç»“æ„
    preview_output_structure(OUTPUT_ROOT, SCALE_FACTORS, category_info)
    
    # ç¡®è®¤å¤„ç†
    estimated_files = len(image_paths) * len(SCALE_FACTORS) * 2  # æ¯ä¸ªscale factorç”Ÿæˆ2ä¸ªæ–‡ä»¶
    print(f"\nğŸ“‹ å¤„ç†è®¡åˆ’:")
    print(f"  - è¾“å…¥å›¾åƒ: {len(image_paths)} å¼ ")
    print(f"  - Scale factors: {len(SCALE_FACTORS)} ä¸ª")
    print(f"  - é¢„è®¡ç”Ÿæˆ: {estimated_files} ä¸ªæ–‡ä»¶")
    
    response = input(f"\nâ“ ç¡®è®¤å¼€å§‹å¤„ç†? (y/n): ").lower().strip()
    if response != 'y':
        print("âŒ å·²å–æ¶ˆå¤„ç†")
        return
    
    # å¼€å§‹å¤„ç†
    generate_lr_images(image_paths, OUTPUT_ROOT, SCALE_FACTORS, TARGET_SIZE)

# ========== å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ ==========
def parse_args():
    parser = argparse.ArgumentParser(description='ç”ŸæˆOSTæ•°æ®é›†çš„ä½åˆ†è¾¨ç‡ç‰ˆæœ¬')
    parser.add_argument('--input', '-i', type=str, default='./OST',
                       help='è¾“å…¥æ•°æ®é›†ç›®å½• (é»˜è®¤: ./OST)')
    parser.add_argument('--output', '-o', type=str, default='./OST_LR',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤: ./OST_LR)')
    parser.add_argument('--scales', '-s', type=int, nargs='+', default=[4],
                       help='é™è´¨å€æ•°åˆ—è¡¨ (é»˜è®¤: [4])')
    parser.add_argument('--size', type=int, default=512,
                       help='ç›®æ ‡å›¾åƒå°ºå¯¸ (é»˜è®¤: 512)')
    parser.add_argument('--sample', type=float, default=1.0,
                       help='é‡‡æ ·æ¯”ä¾‹ (é»˜è®¤: 1.0, å¤„ç†å…¨éƒ¨)')
    parser.add_argument('--method', type=str, default='cubic',
                       choices=['nearest', 'linear', 'cubic'],
                       help='æ’å€¼æ–¹æ³• (é»˜è®¤: cubic)')
    parser.add_argument('--auto', action='store_true',
                       help='è‡ªåŠ¨å¤„ç†ï¼Œè·³è¿‡ç¡®è®¤')
    
    return parser.parse_args()

if __name__ == '__main__':
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    
    # æ›´æ–°å…¨å±€é…ç½®
    DATA_ROOT = args.input
    OUTPUT_ROOT = args.output
    SCALE_FACTORS = args.scales
    TARGET_SIZE = args.size
    SAMPLE_RATIO = args.sample
    PROCESS_ALL = args.sample >= 1.0
    
    # è®¾ç½®æ’å€¼æ–¹æ³•
    method_map = {
        'nearest': cv2.INTER_NEAREST,
        'linear': cv2.INTER_LINEAR,
        'cubic': cv2.INTER_CUBIC
    }
    INTERPOLATION_METHOD = method_map[args.method]
    
    if args.auto:
        # è‡ªåŠ¨æ¨¡å¼ï¼šç›´æ¥å¤„ç†ï¼Œä¸éœ€è¦ç¡®è®¤
        image_paths, category_info = get_all_image_paths(DATA_ROOT, SAMPLE_RATIO)
        if len(image_paths) > 0:
            generate_lr_images(image_paths, OUTPUT_ROOT, SCALE_FACTORS, TARGET_SIZE)
        else:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶!")
    else:
        # äº¤äº’æ¨¡å¼
        main()
