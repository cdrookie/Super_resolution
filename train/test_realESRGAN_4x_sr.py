# ========== Real-ESRGAN 4xè¶…åˆ†è¾¨ç‡æµ‹è¯•è„šæœ¬ ==========
import os
import torch
import numpy as np
from PIL import Image
import torch.nn.functional as F
import time
import argparse

# å¯¼å…¥Real-ESRGANæ¨¡å‹
from basicsr.archs.rrdbnet_arch import RRDBNet

# ========== æ¨¡å‹é…ç½® ==========
MODEL_CONFIGS = {
    'ultra_lite': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 32, 'num_block': 12, 'num_grow_ch': 16
    },
    'lite': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 48, 'num_block': 16, 'num_grow_ch': 24
    },
    'standard': {
        'num_in_ch': 3, 'num_out_ch': 3,  # RGBå½©è‰²å›¾åƒ
        'num_feat': 64, 'num_block': 23, 'num_grow_ch': 32
    }
}

class SuperResolutionTester:
    """4xè¶…åˆ†è¾¨ç‡æµ‹è¯•å™¨"""
    
    def __init__(self, model_path, model_config='lite', device=None):
        self.model_path = model_path
        self.model_config = model_config
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åŠ è½½æ¨¡å‹
        self.model = self.load_model()
        
        print(f"ğŸš€ è¶…åˆ†è¾¨ç‡æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“± è®¾å¤‡: {self.device}")
        print(f"ğŸ§  æ¨¡å‹é…ç½®: {model_config}")
        print(f"ğŸ“„ æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"ğŸ” åŠŸèƒ½: 256Ã—256 RGB â†’ 1024Ã—1024 RGB (4xè¶…åˆ†è¾¨ç‡)")
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„è¶…åˆ†è¾¨ç‡æ¨¡å‹"""
        config = MODEL_CONFIGS[self.model_config]
        model = RRDBNet(**config)
        
        if os.path.exists(self.model_path):
            print(f"âœ… åŠ è½½æ¨¡å‹æƒé‡: {self.model_path}")
            state_dict = torch.load(self.model_path, map_location=self.device)
            model.load_state_dict(state_dict)
        else:
            print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
            print("å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•")
        
        model.to(self.device)
        model.eval()
        
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ğŸ“Š æ¨¡å‹å‚æ•°: {total_params:,} ({total_params/1e6:.2f}M)")
        
        return model
    
    def preprocess_image(self, image_path, target_size=256):
        """é¢„å¤„ç†è¾“å…¥å›¾åƒ"""
        # åŠ è½½å›¾åƒ
        img = Image.open(image_path).convert('RGB')
        original_size = img.size
        
        # è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸ (256x256)
        img_resized = img.resize((target_size, target_size), Image.LANCZOS)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶å½’ä¸€åŒ–
        img_array = np.array(img_resized).astype('float32') / 255.0
        
        # è½¬æ¢ä¸ºCHWæ ¼å¼
        img_array = np.transpose(img_array, (2, 0, 1))  # HWC -> CHW
        
        # æ·»åŠ batchç»´åº¦å¹¶è½¬æ¢ä¸ºtensor
        img_tensor = torch.from_numpy(img_array).unsqueeze(0).to(self.device)
        
        return img_tensor, original_size
    
    def postprocess_image(self, tensor):
        """åå¤„ç†è¾“å‡ºtensor"""
        # ç§»é™¤batchç»´åº¦
        tensor = tensor.squeeze(0)
        
        # è£å‰ªåˆ°[0,1]èŒƒå›´
        tensor = torch.clamp(tensor, 0, 1)
        
        # è½¬æ¢ä¸ºnumpy
        img_array = tensor.cpu().numpy()
        
        # è½¬æ¢ä¸ºHWCæ ¼å¼
        img_array = np.transpose(img_array, (1, 2, 0))  # CHW -> HWC
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        img_array = (img_array * 255).astype('uint8')
        img_pil = Image.fromarray(img_array)
        
        return img_pil
    
    def super_resolve_single(self, input_path, output_path):
        """å¯¹å•å¼ å›¾åƒè¿›è¡Œ4xè¶…åˆ†è¾¨ç‡"""
        start_time = time.time()
        
        # é¢„å¤„ç†
        lr_tensor, original_size = self.preprocess_image(input_path)
        
        print(f"ğŸ“¥ è¾“å…¥å›¾åƒ: {input_path}")
        print(f"ğŸ“ åŸå§‹å°ºå¯¸: {original_size}")
        print(f"ğŸ“ æ¨¡å‹è¾“å…¥: {lr_tensor.shape}")
        
        # æ¨¡å‹æ¨ç†
        with torch.no_grad():
            sr_tensor = self.model(lr_tensor)
        
        print(f"ğŸ“ æ¨¡å‹è¾“å‡º: {sr_tensor.shape}")
        
        # åå¤„ç†
        sr_image = self.postprocess_image(sr_tensor)
        
        # ä¿å­˜ç»“æœ
        sr_image.save(output_path)
        
        process_time = time.time() - start_time
        
        print(f"ğŸ’¾ è¾“å‡ºå›¾åƒ: {output_path}")
        print(f"ğŸ“ è¾“å‡ºå°ºå¯¸: {sr_image.size}")
        print(f"â±ï¸  å¤„ç†æ—¶é—´: {process_time:.2f}ç§’")
        print(f"ğŸ¯ æ”¾å¤§å€æ•°: 4x (256â†’1024)")
        
        return sr_image
    
    def super_resolve_batch(self, input_dir, output_dir, max_images=None):
        """æ‰¹é‡è¶…åˆ†è¾¨ç‡å¤„ç†"""
        if not os.path.exists(input_dir):
            print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
            return
        
        os.makedirs(output_dir, exist_ok=True)
        
        # æ”¯æŒçš„å›¾åƒæ ¼å¼
        supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        
        # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
        image_files = []
        for file in os.listdir(input_dir):
            if os.path.splitext(file.lower())[1] in supported_formats:
                image_files.append(file)
        
        if max_images:
            image_files = image_files[:max_images]
        
        print(f"ğŸ” æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒè¿›è¡Œå¤„ç†")
        print(f"ğŸ“ è¾“å…¥ç›®å½•: {input_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        total_start_time = time.time()
        
        for i, filename in enumerate(image_files, 1):
            input_path = os.path.join(input_dir, filename)
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
            name, ext = os.path.splitext(filename)
            output_filename = f"{name}_4x_sr.png"
            output_path = os.path.join(output_dir, output_filename)
            
            print(f"\n[{i}/{len(image_files)}] å¤„ç†: {filename}")
            
            try:
                self.super_resolve_single(input_path, output_path)
                print(f"âœ… å®Œæˆ")
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
        
        total_time = time.time() - total_start_time
        print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.1f}ç§’")
        print(f"âš¡ å¹³å‡æ¯å¼ : {total_time/len(image_files):.1f}ç§’")
    
    def compare_results(self, lr_path, hr_path, sr_path):
        """æ¯”è¾ƒä½åˆ†è¾¨ç‡ã€é«˜åˆ†è¾¨ç‡å’Œè¶…åˆ†è¾¨ç‡ç»“æœ"""
        # åŠ è½½å›¾åƒ
        lr_img = Image.open(lr_path).convert('RGB')
        hr_img = Image.open(hr_path).convert('RGB') if os.path.exists(hr_path) else None
        sr_img = Image.open(sr_path).convert('RGB')
        
        print(f"\nğŸ“Š ç»“æœæ¯”è¾ƒ:")
        print(f"ğŸ”¹ ä½åˆ†è¾¨ç‡ (è¾“å…¥): {lr_img.size}")
        print(f"ğŸ”¹ è¶…åˆ†è¾¨ç‡ (è¾“å‡º): {sr_img.size}")
        if hr_img:
            print(f"ğŸ”¹ é«˜åˆ†è¾¨ç‡ (çœŸå®): {hr_img.size}")
        
        # åˆ›å»ºå¯¹æ¯”å›¾åƒ
        if hr_img:
            # è°ƒæ•´æ‰€æœ‰å›¾åƒåˆ°ç›¸åŒå°ºå¯¸è¿›è¡Œæ¯”è¾ƒ
            target_size = (1024, 1024)
            lr_resized = lr_img.resize(target_size, Image.NEAREST)  # æœ€è¿‘é‚»æ”¾å¤§
            hr_resized = hr_img.resize(target_size, Image.LANCZOS)
            sr_resized = sr_img.resize(target_size, Image.LANCZOS)
            
            # åˆ›å»ºæ°´å¹³æ‹¼æ¥çš„å¯¹æ¯”å›¾
            comparison = Image.new('RGB', (target_size[0] * 3, target_size[1]))
            comparison.paste(lr_resized, (0, 0))
            comparison.paste(sr_resized, (target_size[0], 0))
            comparison.paste(hr_resized, (target_size[0] * 2, 0))
            
            comparison_path = sr_path.replace('.png', '_comparison.png')
            comparison.save(comparison_path)
            print(f"ğŸ’¾ å¯¹æ¯”å›¾åƒ: {comparison_path}")
            print(f"ğŸ“‹ å¸ƒå±€: ä½åˆ†è¾¨ç‡ | è¶…åˆ†è¾¨ç‡ | é«˜åˆ†è¾¨ç‡")
        
        return sr_img

def main():
    parser = argparse.ArgumentParser(description='Real-ESRGAN 4xè¶…åˆ†è¾¨ç‡æµ‹è¯•')
    parser.add_argument('--model', type=str, default='./realESRGAN_4x_super_resolution.pth',
                        help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--config', type=str, default='lite', 
                        choices=['ultra_lite', 'lite', 'standard'],
                        help='æ¨¡å‹é…ç½®')
    parser.add_argument('--input', type=str, required=True,
                        help='è¾“å…¥å›¾åƒæˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--output', type=str, required=True,
                        help='è¾“å‡ºå›¾åƒæˆ–ç›®å½•è·¯å¾„')
    parser.add_argument('--mode', type=str, default='single', 
                        choices=['single', 'batch'],
                        help='å¤„ç†æ¨¡å¼: single(å•å¼ ) æˆ– batch(æ‰¹é‡)')
    parser.add_argument('--max_images', type=int, default=None,
                        help='æ‰¹é‡å¤„ç†æ—¶çš„æœ€å¤§å›¾åƒæ•°é‡')
    parser.add_argument('--compare', type=str, default=None,
                        help='ç”¨äºæ¯”è¾ƒçš„é«˜åˆ†è¾¨ç‡å›¾åƒè·¯å¾„(ä»…å•å¼ æ¨¡å¼)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = SuperResolutionTester(args.model, args.config)
    
    if args.mode == 'single':
        # å•å¼ å›¾åƒå¤„ç†
        print(f"\nğŸ¯ å•å¼ å›¾åƒè¶…åˆ†è¾¨ç‡å¤„ç†")
        sr_image = tester.super_resolve_single(args.input, args.output)
        
        # å¦‚æœæä¾›äº†é«˜åˆ†è¾¨ç‡å›¾åƒè¿›è¡Œæ¯”è¾ƒ
        if args.compare:
            tester.compare_results(args.input, args.compare, args.output)
    
    elif args.mode == 'batch':
        # æ‰¹é‡å¤„ç†
        print(f"\nğŸ¯ æ‰¹é‡è¶…åˆ†è¾¨ç‡å¤„ç†")
        tester.super_resolve_batch(args.input, args.output, args.max_images)

if __name__ == '__main__':
    print("=" * 70)
    print("ğŸš€ Real-ESRGAN 4xè¶…åˆ†è¾¨ç‡æµ‹è¯•å·¥å…·")
    print("=" * 70)
    
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œæ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    import sys
    if len(sys.argv) == 1:
        print("ğŸ“– ä½¿ç”¨ç¤ºä¾‹:")
        print("\n1. å•å¼ å›¾åƒè¶…åˆ†è¾¨ç‡:")
        print("   python test_realESRGAN_4x_sr.py --input test.jpg --output test_4x.png --mode single")
        print("\n2. æ‰¹é‡å¤„ç†:")
        print("   python test_realESRGAN_4x_sr.py --input ./inputs --output ./outputs --mode batch")
        print("\n3. ä¸é«˜åˆ†è¾¨ç‡å›¾åƒå¯¹æ¯”:")
        print("   python test_realESRGAN_4x_sr.py --input lr.jpg --output sr.png --compare hr.jpg --mode single")
        print("\n4. ä½¿ç”¨ä¸åŒæ¨¡å‹é…ç½®:")
        print("   python test_realESRGAN_4x_sr.py --input test.jpg --output test_4x.png --config standard")
        print("\nğŸ“ å‚æ•°è¯´æ˜:")
        print("   --model: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„")
        print("   --config: æ¨¡å‹é…ç½® (ultra_lite/lite/standard)")
        print("   --input: è¾“å…¥å›¾åƒæˆ–ç›®å½•")
        print("   --output: è¾“å‡ºå›¾åƒæˆ–ç›®å½•")
        print("   --mode: å¤„ç†æ¨¡å¼ (single/batch)")
        print("   --max_images: æ‰¹é‡å¤„ç†çš„æœ€å¤§å›¾åƒæ•°")
        print("   --compare: ç”¨äºæ¯”è¾ƒçš„é«˜åˆ†è¾¨ç‡å›¾åƒ")
        print("\nğŸ” åŠŸèƒ½: å°†256Ã—256å›¾åƒæ”¾å¤§åˆ°1024Ã—1024 (4xè¶…åˆ†è¾¨ç‡)")
        sys.exit(0)
    
    main()
